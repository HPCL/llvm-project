This document describes the current design of Clacc, which extends
Clang and LLVM with support for OpenACC.

Design Rationale
================

This document focuses on the details of the current Clacc design and
only summarizes the design rationale.  A more complete description of
the design rationale, including a presentation of several design
alternatives that were considered, appears in sections I through II.D
of the following paper:

> Clacc: Translating OpenACC to OpenMP in Clang, Joel E. Denny, Seyong
> Lee, and Jeffrey S. Vetter, 2018 IEEE/ACM 5th Workshop on the LLVM
> Compiler Infrastructure in HPC (LLVM- HPC), Dallas, TX, USA, (2018).

High-Level Design
=================

A key feature of Clacc's design is to translate OpenACC to OpenMP in
order to build on Clang's existing OpenMP compiler and runtime
support.  Clacc performs this translation at the AST level, producing
AST representations of both the original OpenACC and the generated
OpenMP.  As such, Clacc's design is depicted abstractly in the
following figure:

```
   OpenACC source
         |
         | parser
         v
    OpenACC AST
         |
         | TransformACCToOMP
         v
    OpenMP AST
         |
         | codegen
         v
      LLVM IR
         |
         | LLVM
         v
    executable
  OpenACC runtime
   OpenMP runtime
```

The components of this diagram are as follows:

* **OpenACC source** is C application source code containing OpenACC
  constructs.  C++ will be supported in the future.  Currently,
  Fortran support is not planned and would not be based on Clang.
* **Parser** is the existing Clang parser and semantic analyzer
  extended for OpenACC.
* **OpenACC AST** is a Clang AST in which OpenACC constructs are
  represented by OpenACC node types, which are a Clacc extension to
  Clang.
* **`TransformACCToOMP`** is a new Clang component introduced by Clacc
  to transform OpenACC to OpenMP entirely at the AST level.
* **OpenMP AST** is a Clang AST in which OpenACC constructs have been
  lowered to OpenMP constructs represented by OpenMP node types, which
  exist in Clang independently of Clacc.
* **Codegen** is the existing Clang backend, which lowers the OpenMP
  AST to LLVM IR.
* **LLVM IR** is the usual LLVM intermediate representation
  generated by Clang for an OpenMP AST.
* **LLVM** consists of all LLVM optimization passes and backends that
  lower LLVM IR into object form.
* **Executable** is the final application executable.
* **OpenACC runtime** is built on top of LLVM's existing **OpenMP
  runtime** with extensions for OpenACC's run-time environment
  variables, library API, etc.

This design has a number of advantages.  First, the construction of an
OpenACC AST should facilitate the development of additional OpenACC
source-level tools, such as pretty printers, static analyzers,
lint-like tools, and debugger and editor extensions.  The construction
of an OpenMP AST should facilitate a number of non-traditional
user-level compiler features, such as automated porting of OpenACC
applications to OpenMP, and reuse of existing OpenMP tools for
OpenACC.  Because the OpenACC syntax and OpenMP syntax are so similar,
simple translations from OpenACC to OpenMP are easier to implement at
the AST level than as part of a later compiler stage.  Finally,
because the AST is the highest-level representation, implementing at
the AST level maximizes the amount of the existing OpenMP
implementation that Clacc can reuse.

It is important to understand that the above description is abstract.
Specifically, as described in the next section, `TransformACCToOMP` is
not a distinct compiler phase, and the OpenACC AST and OpenMP AST are
actually represented within a single Clang AST.

TransformACCToOMP
=================

A key issue in transforming OpenACC to OpenMP in Clang ASTs is that
Clang ASTs are designed to be immutable once constructed.  This
immutability property might at first seem to make Clacc's
`TransformACCToOMP` component impossible to implement, but it does
not.  In this section, we describe Clang's `TreeTransform` facility
and explain how `TransformACCToOMP` employs it to cleanly work around
this immutability property.

Background: TreeTransform
-------------------------

Independently of Clacc, Clang uses the `TreeTransform` facility to
transform C++ templates for the sake of instantiating them.  When the
parser reaches a template instantiation in the source code,
`TreeTransform` builds a transformed copy of the AST subtree that
represents the template, and it inserts that copy into the AST.  This
insertion is part of the normal process of extending the AST during
parsing and so does not violate AST immutability.

`TreeTransform`'s design has some convenient properties for Clacc's
purposes:

* **Extensibility**: `TreeTransform` is a class template employing the
  curiously recurring template pattern (CRTP) for static polymorphism.
  Thus, it is possible to override default behavior that is reasonable
  for C++ template instantiation but not for translation from OpenACC
  to OpenMP.
* **Encapsulation of `Sema`**: `TreeTransform`'s interface serves as a
  convenient encapsulation of semantic actions that are normally
  called during parsing.  This encapsulation enables Clacc to call
  those actions to build OpenMP ASTs without developing fragile
  dependencies on the current OpenMP implementation within `Sema`.

However, there are also some caveats to consider for `TreeTransform`:

* **Transitory semantic data**: To build new nodes, `TreeTransform`
  runs many of the same semantic actions that the parser normally
  runs.  Those semantic actions require the transitory semantic data
  that has been stored in Clang's `Sema` object by the time the parser
  reaches the syntactic context where new nodes are to be inserted,
  but the parser gradually discards some of that semantic data as the
  parser progresses to other syntactic contexts.  Thus,
  `TreeTransform` cannot be run on arbitrary nodes in the AST at
  arbitrary times.  For example, to run `TreeTransform` on arbitrary
  nodes in a translation unit after the parsing of that translation
  unit has completed, it might be necessary to transform the
  translation unit's entire AST in order to rebuild all of the
  necessary transitory semantic metadata.
* **Permanent semantic data**: Currently, parsing a C++ template
  permanently associates semantic data with that template's AST
  subtree in a way that's compatible with later runs of
  `TreeTransform` for instantiations of that template.  However,
  there's no guarantee that semantic data that is reasonable for C++
  template instantiation will be compatible with any arbitrary
  extension of `TreeTransform`.  For example, we have noticed that, if
  we write a simple `TreeTransform` extension that merely duplicates
  an OpenMP region immediately after that region's node is
  constructed, the default `TreeTransform` implementation does not
  update the declaration contexts for variable declarations that are
  local to the duplicate region (see `TreeTransform::TransformDecl`),
  so those duplicate variables appear to be declared in the original
  region, resulting in spurious compiler diagnostics.
* **Redundant AST subtrees**: As described above, `TreeTransform` is
  designed to construct modified versions of existing subtrees, and it
  is not designed to remove the original subtrees.  This behavior
  makes sense for C++ template instantiation because the original
  template must remain in the AST for additional instantiations.
  Moreover, the template and its instantiations represent distinct
  regions of the original source.  However, in the case of Clacc, an
  OpenACC subtree and the OpenMP subtree to which it is translated
  represent different versions of the same region of the source, so
  AST iterations must take special care not to visit both when they're
  expecting only one version of the source.

Design
------

Clacc's `TransformACCToOMP` component is implemented as a class
derived via CRTP from `TreeTransform`.  As mentioned earlier,
`TransformACCToOMP` does not represent a distinct compiler phase.
Instead, immediately after parsing each OpenACC region and
constructing an associated OpenACC subtree, Clacc passes the OpenACC
subtree to `TransformACCToOMP` to construct the corresponding OpenMP
subtree.  Clacc adds the resulting OpenMP subtree's root as a hidden
child of the OpenACC subtree's root, and then parsing continues.

For example, consider this function written in OpenACC, where comments
show the equivalent OpenMP:

```
void foo() {
  #pragma acc parallel  // #pragma omp target teams
  #pragma acc loop gang // #pragma omp distribute
  for (int i=0; i<2; ++i)
    // loop body
}
```

The AST that Clacc constructs is depicted below:

```
       TranslationUnit
              |
         FunctionDecl
              |
         CompoundStmt
              |
     ACCParallelDirective
              |          `-OMPNode-> OMPTargetTeamsDirective
       ACCLoopDirective                         |
            /   \      `---OMPNode---> OMPDistributeDirective
ACCGangClause   ForStmt                         |
                   |                         ForStmt
                                                |
```

Thus, the `ForStmt` node and its subtree are duplicated.  The
`ACCLoopDirective` node is translated to an `OMPDistributeDirective`
node, which becomes the normal parent for the translated `ForStmt`
node and the hidden OpenMP child for the `ACCLoopDirective` node.
Finally, the `ACCParallelDirective` is translated to an
`OMPTargetTeamsDirective` node, which becomes the normal parent for
the `OMPDistributeDirective` node and the hidden OpenMP child for the
`ACCParallelDirective` node.

Clacc overcomes the `TreeTransform` caveats discussed in the previous
section as follows:

* **Transitory semantic data**: Because Clacc calls
  `TransformACCToOMP` immediately after constructing an OpenACC
  subtree, the exact transitory semantic data needed to construct the
  corresponding OpenMP subtree is present.
* **Permanent semantic data**: So far, Clacc is able to override
  specific `TreeTransform` functionality in order to transform
  semantic data that would be permanent across C++ template
  instantiation but that must be different between OpenACC and OpenMP
  subtrees.
* **Redundant AST subtrees**: AST traversals are typically based on
  Clang's `RecursiveASTVisitor` facility.  Most AST traversal
  developers and users likely expect for traversals to visit an AST
  representing the original source code only.  Because the OpenMP node
  to which an OpenACC node is translated is not recorded as a normal
  child of the OpenACC node, `RecursiveASTVisitor` visits the OpenACC
  node but skips its hidden OpenMP child.  However, while visiting an
  OpenACC node, a visitor can be written to call the node's
  `getOMPNode` member function to access the OpenMP node, possibly for
  a recursive visitation.

As a result, Clacc supports at least three kinds of AST traversals:

* **Visit OpenACC only**: For example, `-ast-print` is an existing
  Clang command-line option for translating the Clang AST back to
  source.  Because the output of `-ast-print` has thus always
  corresponded to the original preprocessed input and never a lowered
  version of it, Clacc extends it for OpenACC not to include the
  OpenMP translation.  In the previous example, `-ast-print` thus
  visits the `ACCParallelDirective` node, the `ACCLoopDirective` node,
  and the original `ForStmt` subtree but not the
  `OMPTargetTeamsDirective` node, the `OMPDistributeDirective` node,
  or the translated `ForStmt` subtree.
* **Delegate to OpenMP**: For example, one of the major motivations
  for translating the OpenACC AST to an OpenMP AST is to reuse the
  existing LLVM IR codegen implementation for OpenMP.  Thus, for LLVM
  IR codegen, each OpenACC node delegates to its hidden OpenMP child.
  In the previous example, the `ACCParallelDirective` node delegates
  LLVM IR codegen to the `OMPTargetTeamsDirective` node and its
  subtree, and the normal subtree of the `ACCParallelDirective` node
  is not visited.
* **Visit OpenACC and OpenMP**: For example, `-ast-dump` is an
  existing Clang command-line option for printing a textual
  representation of the AST structure, including parent-child
  relationships, source location information, and computed types.
  This feature is clearly designed for debugging ASTs and is very
  useful for Clang developers.  For each OpenACC AST node, Clacc
  extends this feature to always produce a full representation of that
  node's subtree including, as a specially marked child, the OpenMP
  subtree to which it translates.

Redundant AST subtrees might at first seem to be a disadvantage of
employing `TreeTransform` in `TransformACCToOMP`.  However, because it
results in a representation of the chosen mapping from OpenACC to
OpenMP, we believe it augments the potential for constructing flexible
debugging and analysis tools on top of Clacc.  The capabilities of
`-ast-dump`, as described above, and `-fopenacc-print`, as described
in the next section, are simple examples.

Codegen
=======

As mentioned in the previous section, an OpenACC AST node implements
LLVM IR codegen by delegating to its hidden OpenMP child.  The most
obvious points for this implementation are the OpenACC cases in the
main switch on AST node types within Clang codegen's
`CodeGenFunction::EmitStmt`.

While necessary, those implementation points are insufficient for
offloading support.  The trouble is that the OpenMP codegen
implementation also has a hook into Clang's codegen framework outside
that switch.  This hook calls
`CGOpenMPRuntime::scanForTargetRegionsFunctions`, which recurses
through AST nodes looking for OpenMP target regions to emit in
separate device functions.  Thus, Clacc extends this scan to look for
OpenACC AST nodes and, as before, to delegate the required codegen to
their hidden OpenMP children.

Source-to-Source Translation
============================

The `TransformACCToOMP` section described how Clacc uses Clang's
`TreeTransform` facility to construct and attach hidden OpenMP
subtrees to OpenACC subtrees.  It also mentions that `-ast-print`
prints only OpenACC.  In this section, we describe Clang's `Rewrite`
facility, which is normally used in Clang for source-to-source
translation, and we describe how Clacc prints OpenMP source.

Background: Rewrite
-------------------

The `Rewrite` facility in Clang is used in tools like `clang-format`
and `clang-tidy` to perform source-to-source translation.  However,
`Rewrite` does not perform AST transformations.  Instead, `Rewrite`
provides an API for making textual modifications to Clang's input
buffer, which contains the original input source code, while using the
Clang AST to guide those modifications.

To produce a transformed AST, the transformed source from `Rewrite`
must be parsed anew by Clang to construct an entirely separate AST.
For this reason, `Rewrite` is most useful for implementing a single
transformation pass whose output is source.  `Rewrite` is not
efficient for successive transformation passes or for LLVM IR codegen.
Direct AST transformations are better for those purposes.

Because traditional OpenACC compilation is a major use case for Clacc,
and because for Clang that requires LLVM IR codegen, we chose
`TreeTransform` not `Rewrite` to implement `TransformACCToOMP`.
However, source-to-source translation is also a Clacc use case, and,
as discussed in the next section, `Rewrite` is helpful there after
`TransformACCToOMP`.

Design
------

To enable source-to-source translation from the Clang command line,
Clacc supports two new Clang command-line options: `-fopenacc-print`,
which is built on `Rewrite`, and `-fopenacc-ast-print`, which is built
on `-ast-print`.  Each takes any of the following values:

* `acc`: OpenACC constructs are printed and the OpenMP constructs to
  which they were translated are ignored.  Thus, this value is likely
  not helpful to users but can be helpful to developers for debugging
  the Clacc implementation.  That is, `-fopenacc-print=acc` merely
  prints the original source without modification, and
  `-fopenacc-ast-print=acc` is a more convenient form of `-Xclang
  -ast-print -fsyntax-only -fopenacc`.
* `omp`: OpenMP constructs are printed, and the OpenACC constructs
  from which they were translated are ignored.
* `acc-omp`: OpenACC constructs are printed and the OpenMP constructs
  to which they were translated are printed in neighboring comments.
* `omp-acc`: OpenMP constructs are printed and the OpenACC constructs
  from which they were translated are printed in neighboring comments.

In the last two cases, Clacc will avoid duplicating the code block
associated with a directive if that code block prints identically in
both the OpenACC and OpenMP versions.  The output then looks similar
to the code passage in the previous example.

Originally, Clacc only supported the functionality of
`-fopenacc-ast-print` (but under a different name).  Because it's
built on `-ast-print`, its functionality is problematic in several
ways:

* `-ast-print` was designed for debugging and not for faithful
  printing of the AST.  Even so, we have successfully contributed
  upstream a number of fixes to improve the fidelity of its output on
  the grounds that such fixes also improve the debugging use case.
  Still, our hunch is that there is likely much more work to do,
  especially in the case of C++ as we have mostly focused on C so far.
* Because `-ast-print` computes its output from the AST structure, the
  output looks like the output of Clang's preprocessor.  Thus,
  includes and other macros are expanded, and the original formatting
  and comments are lost.  Such mangling of the source is unsuitable
  for permanent migration of an application from OpenACC to OpenMP.
  It's also unsuitable when targeting a different OpenMP compiler
  perhaps for a different target architecture where preprocessor
  macros and includes expand differently.

On the other hand, because `-fopenacc-print` is built on `Rewrite`, it
modifies the original input buffer and thus can avoid these problems
in most cases.  That is, `-fopenacc-print` examines the OpenACC
subtrees and the OpenMP subtrees computed by `TransformACCToOMP` as
needed to modify the input buffer in the manner requested by the
argument to `-fopenacc-print`.  For OpenMP subtrees containing
directives and other code not appearing in the original source and
thus not in the input buffer, it still employs `-ast-print`
functionality, but at least the above problems are not pervasive in
the output.  In the future, we might experiment with using some means
such as source locations to track which portions of an OpenMP subtree
were copied verbatim from the OpenACC subtree and then overriding
`-ast-print` functionality to print just those portions using the
original input buffer.

Interaction with OpenMP Support
===============================

`-fopenmp`
----------

Even though Clacc translates OpenACC to OpenMP, Clacc currently does
not support OpenACC and OpenMP in the same source.  Doing so would
require, for example, extensions to data attribute analyses to
consider the interactions between OpenACC and OpenMP directives and
clauses.  Thus, Clacc reports an error diagnostic if `-fopenmp` is
specified on the Clang command line when OpenACC support is enabled by
any `-fopenacc*` option.  To implement this, Clacc extends the Clang
driver to just pass the relevant command-line options to the Clang
front end, and it extends the front end to produce the error
diagnostic.  Thus, specifying `-cc1` to bypass the driver does not
avoid the error diagnostic.

Discarding OpenMP (`-Wsource-uses-openmp`)
------------------------------------------

As usual when `-fopenmp` is not specified, the front end discards
OpenMP directives in the source during parsing, and
`-Wsource-uses-openmp` is available as usual to request warnings about
them.  Nevertheless, Clacc must enable OpenMP support in the front end
in order to build OpenMP subtrees without failing many assertions in
the OpenMP implementation, but enabling OpenMP support normally
prevents OpenMP directives from being discarded.  To implement all
this, Clacc extends the front end in two ways: (1) after confirming
the user did not request both OpenACC and OpenMP support, it enables
OpenMP support if OpenACC support is enabled, and (2) it discards
OpenMP directives during parsing if either OpenMP support is disabled
or OpenACC support is enabled.

`-fopenmp-*`
------------

Clacc permits all `-fopenmp-*` command-line options when OpenACC
support is enabled.  These options adjust various OpenMP features when
compiling the OpenMP translation.  To implement this, Clacc extends
Clang to check if OpenACC support is enabled everywhere it already
checks if OpenMP support is enabled.  However, so far, only
`-fopenmp-targets=<triples>` to specify desired offloading targets has
been tested, and it's only been tested for traditional compilation
mode.

It's not clear if `-fopenmp-*` options should be relevant to
source-to-source mode.  First, some options like
`-fopenmp-targets=<triples>` affect the OpenMP version Clang selects
by default, and that can affect semantics, diagnostics, and any
AST-printed code containing `_OPENMP`, but should Clacc let any of
that matter when compiling OpenACC?  Second, in experimental
implementations, we have observed that `-fopenmp-targets=nvptx64` adds
many declarations to the source code printed for `nvptx64`.  Would
offload bundling of the various versions of the source code be useful?

In general, the Clacc user should not have to be aware that OpenMP
support is being utilized when in traditional compilation mode.
However, the need to combine `-fopenmp-targets=<triples>` with
`-fopenacc` to enable offloading, for example, violates that
principle.  Moreover, diagnostics for `-fopenmp-*` are currently
expressed in terms of OpenMP even when OpenACC support is enabled.  In
the future, especially when Clacc is considered for upstreaming, Clacc
might develop its own `-fopenacc-*` options to be used instead.
Nevertheless, for now, we have concluded that the Clacc implementation
will be easier to keep in sync with upstream while the Clacc
implementation reuses the existing `-fopenmp-*` options with minimal
modifications.

`-fopenmp=<lib>`
----------------

Normally, `-fopenmp=<lib>` can be used to specify an alternate OpenMP
library.  However, Clang handles it as an alias for `-fopenmp`, so
it's also expected to enable OpenMP support.  We feel it would be
subtle and surprising to users if Clacc were to suppress the latter
behavior when OpenACC support is enabled, so it is currently not
possible to use `-fopenmp=<lib>` to specify an alternate OpenMP
library when OpenACC support is enabled.  Options like `-L` and `-l`
must be used instead.

OpenACC to OpenMP Mapping
=========================

This section details Clacc's planned mapping from OpenACC directives
and clauses to OpenMP directives and clauses.  If an OpenACC directive
or clause does not appear in this section, we haven't planned it yet.
`README-OpenACC-status.md` lists which OpenACC directives and clauses
Clacc already implements.

Notation
--------

For conciseness, we use the following notation when describing clauses
and data attributes:

* *exp* labels a clause, possibly specifying a data attribute, that is
  explicitly specified in the source.
* *pre* labels a data attribute that is predetermined by the compiler
  (that is, cannot be overridden by an *exp* clause) and is not
  specified by an *exp* clause.
* *imp* labels a data attribute that is implicitly determined by the
  compiler (that is, can be overridden by an *exp* clause) and is not
  specified by an *exp* clause.
* *not* labels a clause that is not *exp*.
* The notation *L C* -> *L' C'* specifies that clause or data
  attribute *C* under the condition identified by label *L* maps to
  clause or data attribute *C'* under the condition identified by
  label *L'*, where a label is *exp*, *pre*, *imp*, or *not*.
* The notation *L*|*L' C* -> *L'' C'* specifies both of the following
  mappings:
    * *L C* -> *L'' C'*
    * *L' C* -> *L'' C'*
* Mappings for per-variable data attributes and clauses are per
  variable and per directive.
* Mappings for other clauses are per directive.
* Where arguments to clauses are not specified on either end of the
  mapping, the mapping maintains the arguments as they are even if the
  clause name or position changes.

Prescriptive vs. Descriptive OpenACC
------------------------------------

The mapping in this section represents a conservative choice intended
to always achieve correct OpenACC behavior.  As Clacc evolves to
support a descriptive interpretation of OpenACC and the requisite
compiler analyses, this mapping will represent the base choice from
which Clacc will look for deviations to improve performance of the
application, and this mapping will represent the fall back choice if
Clacc fails to find better mappings.  Under Clacc's current
prescriptive interpretation of OpenACC, Clacc supports no such
analyses and so effectively always falls back to this mapping.

Explicit vs. Implicit OpenMP Clauses
------------------------------------

One theme throughout Clacc's mapping is that Clacc does not rely on
implicit or predetermined attributes of OpenMP except for cases where
an explicit clause is not permitted or is difficult to produce.  That
is, Clacc tries to make the exact behavior it intends to produce as
explicit as possible in the generated OpenMP for the sake of
debugging. Thus, -> *exp* appears frequently below.

Clause Aliases
--------------

Some OpenACC clauses, such as `pcopy`, are aliases for others clauses,
such as `copy`.  Clacc handles the semantics and mapping for a clause
alias the same as for the aliased clause, so clause aliases are not
documented further in this section.

Semantic Clarifications
-----------------------

While developing this mapping, we found we had to make assumptions
about some aspects of OpenACC semantics in C that are not clear in the
OpenACC specification.  In many cases, it was the related behavior of
the Clang OpenMP implementation that brought the need for those
assumptions to our attention.  We describe those assumptions in this
section.  We are working with the OpenACC technical committee to
clarify these points in future versions of the OpenACC specification.

### Basic Data Attributes ###

* Clacc models data attributes (DAs) by partitioning them into two
  groups:
    * Data mapping attributes (DMAs), which describe the mapping and
      transfer of data between host and device:
        * `nomap` (default)
        * `copy`
        * `copyin`
        * `copyout`
        * Others not yet implemented by Clacc.
    * Data sharing attributes (DSAs), which describe the sharing of
      data among gangs, workers, or vector lanes:
        * `shared` (default, mappable)
        * `reduction` (mappable)
        * `firstprivate` (unmappable)
        * `private` (unmappable)
    * DA combinations:
        * Every variable referenced in a construct and declared
          outside it has at most one DMA and one DSA on the associated
          directive.
        * Mappable DSAs can be combined with any DMA.
        * Unmappable DSAs can be combined with `nomap` but no other
          DMA.
        * The restrictions for *exp* DAs that enforce these rules are
          discussed later in this section.
    * Relevant DAs:
        * A variable cannot have any DA from a group on a directive if
          that group is irrelevant to that directive.
        * DMAs are relevant only to `acc parallel`.
        * DSAs are relevant only to `acc parallel` and `acc loop`.
        * Relevance does not indicate that all members of a group are
          permitted.  For example, `firstprivate` is not permitted on
          `acc loop`.
    * Default DA:
        * Each group has one default DA.
        * It is not permitted as *exp* and is never computed as *pre*.
        * It is computed as *imp* for a variable on a directive if (1)
          the group is relevant to the directive and (2) there is no
          other *exp*, *pre*, or *imp* DA from that group for that
          variable on that directive.
        * `nomap` indicates no data mapping of a variable between
          device and host.
        * `shared` indicates no privatization of a variable.  That is,
          references to the variable within the construct refer to the
          original variable, which is shared among the gangs, workers,
          or vector lanes executing the construct.
    * Notes:
        * The OpenACC 3.0 specification does not categorize DAs into
          these groups, and this categorization is not strictly
          necessary to specify OpenACC semantics unambiguously.
          However, Clacc employs this categorization as it seems to
          simplify and clarify documentation, discussion, and
          implementation.
        * The OpenMP 5.0 specification does employ these two groups
          with the same high-level semantics (but the DAs within the
          groups are not precisely the same as in Clacc).  Thus,
          additional benefits of employing this categorization in
          Clacc are that it might prove recognizable to potential
          Clacc contributors and that it facilitates OpenACC
          translation to OpenMP.
        * The default DA in each group is not specified as a DA by
          OpenACC 3.0:
            * As noted in the mappings below, Clacc does not translate
              `nomap`, which is merely a placeholder indicating no
              mapping attribute was determined.
            * As noted in the mappings below, in many cases, Clacc
              translates `shared` to OpenMP's `shared` clause.
              However, `omp distribute` and `omp simd` do not accept
              *exp* `shared`, so Clacc then relies on OpenMP implicit
              data sharing attributes, and the semantics are the
              desired OpenACC semantics.
        * Otherwise, the DMAs are listed in OpenACC 3.0 sec. 2.7 "Data
          Clauses", and the DSAs are described in the sections for the
          directives that permit them.
* It is an error if, on any OpenACC directive, a variable appears more
  than once per *exp* DA.  Notes:
    * The main motivation for this error is that such redundancy is
      likely a mistake.
    * gcc 7.4.0 also reports errors for this case, but pgcc 19.4-0
      does not.
    * OpenMP 5.0 sec. 2.19.4 p. 282 L7-9 says, "A list item may not
      appear in more than one clause on the same directive, except
      that it may be specified in both firstprivate and lastprivate
      clauses."  Thus, if Clacc did not report such duplicate clauses
      as errors, it would have to discard them when generating OpenMP.
* It is an error if, on any OpenACC directive, a variable appears in
  more than one *exp* DMA.  Notes:
    * In OpenACC 3.0, it seems clear that DMAs are intended to be
      mutually exclusive options along a single dimension.  For
      example, `copy`, `copyin`, and `copyout` have contradictory
      specifications for initialization of the local copy of the
      variable and for storing data back to the original variable.
    * No *pre* DMA is specified by OpenACC 3.0 or implemented by
      Clacc.
* It is an error if, on any OpenACC directive, a variable appears in
  more than one *exp*|*pre* DSA.  Notes:
    * On a non-combined directive, DSAs have contradictory
      specifications for initialization of the local copy of the
      variable and for storing data back to the original variable.
    * On a combined directive, `firstprivate` applies to the effective
      `acc parallel`, but `reduction` and `private` apply to the
      effective `acc loop`.  Thus, specifying a variable in both
      `firstprivate` and either `reduction` or `private` on a combined
      directive might not seem contradictory.  However, it is surely a
      mistake.  In the case of `reduction`, you cannot access the
      reduced value.  In the case of `private`, you cannot access the
      initialized value.  Thus, the above restriction fully applies to
      a combined directive as well.
* It is an error if, on any OpenACC directive, a variable appears in
  an *exp* DMA and an unmappable *exp* DSA.  Notes:
    * Due to variable privatization within the construct, unmappable
      DSAs appear to circumvent the benefits of any reference
      counting, allocations, or data transfers specified by a DMA on
      the same directive.
    * That seems equally true on a combined directive even though DMAs
      apply to the effective `acc parallel` while `private` applies to
      the effective `acc loop`.
    * The only mappable *exp* DSA is `reduction`.  In OpenACC 3.0, it
      is specifically meant to combine with DMAs and even implies a
      DMA, `copy`.
    * TODO: Does any existing OpenACC code combine a DMA with either
      `firstprivate` or `private` expecting the non-privatized device
      copy to be accessed elsewhere or via an alias even though it's
      inaccessible (lexically) within the construct?
* *exp*|*imp* DA for a variable of incomplete type is an error.
  Notes:
    * A private or device copy is assumed to be allocatable in each of
      these cases, but allocation is impossible for incomplete types.
    * It does not appear possible for any DA other than `copy`,
      `nomap`, or `shared` to be *imp* for a variable of incomplete
      type.
* *exp* `private` or *exp* `reduction` for a `const` variable is an
  error.  Notes:
    * Private copies of a `const` private variable would remain
      uninitialized throughout their lifetime.
    * A reduction assigns to both the original variable and the
      private copies after their initialization, but `const` prevents
      that.
    * *exp* `copy` and *exp* `copyout` are strange cases.
      Technically, each assigns to the original, and `const` prevents
      that.  However, there are several arguments for why each should
      be permitted for a `const` variable:
        * For shared memory, it's supposed to be fine to ignore *exp*
          `copy` and *exp* `copyout` (or any DMA) entirely, so `const`
          is harmless in that case.  An implementation for discrete
          memory could optimize by not copying back to the original
          variable because the value shouldn't change because it's
          `const`, so `const` is actually helpful here instead of
          problematic.  In the case of `copyout`, it could be argued
          that the value to be copied back could be an uninitialized
          value instead of the original value, but it could also be
          argued that's poor usage of `copyout`.  TODO: Actually, is
          there any good usage for `copyout` with the `const` case?
        * It should be fine to reference a `const` non-scalar within
          an `acc parallel` region even though the non-scalar is
          declared outside the region, but the `acc parallel` has
          *imp* `copy` for such a non-scalar.  Thus, *imp* `copy` must
          be permitted for the non-scalar, and so then should *exp*
          `copy`.
        * Clacc translates `copy` or `copyout` to OpenMP's `map`
          clause with a map type of `tofrom` or `from`, and the OpenMP
          implementation permits those for `const` variables.
    * *exp* `copyin` or *exp* `firstprivate` is fine for a `const`
      variable.  The local copy will have the original variable's
      value throughout its lifetime.
    * *imp* `copy` or *imp* `firstprivate` for a `const` variable
      should be fine for the same reasons as their *exp* versions.
    * *imp* `nomap` and *imp* `shared` are the only remaining *imp*
      DAs.  These don't imply any specific initialization or other
      write and so should be fine for a `const` variable.
    * `private` is *pre* for loop control variables, but they
      obviously cannot be `const` anyway, so it's a moot point.
* It is an error to specify subarrays with no `:` and one integer.
  Notes:
    * This notation is syntactically identical to an array subscript.
    * Indeed, OpenMP 5.0 sec. 2.1.5 appears to say that, if an array
      section has no `:` and one integer, the one integer is the start
      index and the length is one.  That's also how Clang implements
      it for OpenMP.
    * OpenACC 2.7 does not appear to specify a behavior for this
      notation.  However, in our experiments, pgcc 19.4-0 implements
      it instead as if the start index is zero and the one integer is
      the length.
    * If OpenACC grows a specification for this behavior, we will
      extend Clacc to implement it.  If, before then, we discover
      multiple applications that depend on PGI's current behavior, we
      will consider extending Clacc to implement that.
* It is an error to use subarrays in `firstprivate` and `private`
  clauses.  Notes:
    * While pgcc 19.4-0 does permit subarrays in these clauses,
      OpenACC 2.7 doesn't clarify whether they're permitted, [as has
      been discussed by the OpenACC technical
      committee](https://github.com/OpenACC/openacc-spec/issues/59).
    * OpenMP 5.0 does not permit array sections in these clauses.  See
      OpenMP 5.0 sec. 2.1.5 p. 46 L10.  Thus, this feature is
      currently listed under "Potentially Unmappable Features" below.
* An *imp* `copy` for a reduction variable overrides an *imp*
  `firstprivate` when the variable is a scalar.  Text to make this
  overriding behavior clear has been proposed for inclusion in the
  OpenACC spec after 2.7.
* Identifying a DA as *pre* instead of *imp* only matters for combined
  directives.  Notes:
    * OpenACC 3.0 sec. 2.6 "Data Environment" says "Variables with
      predetermined data attributes may not appear in a data clause
      that conflicts with that data attribute."
        * That is, the difference between *pre* and *imp* is that a
          variable with a *pre* DA is not permitted to have a
          conflicting *exp* data clause, but a variable with an *imp*
          DA is (and then the *imp* DA is overridden).
        * DSAs are not listed in OpenACC 3.0 sec. 2.7 "Data Clauses".
          However, we assume they are also considered data clauses and
          attributes.
        * The definition of "conflicts" is not specified.  We assume a
          conflict is a different data clause or attribute for the
          same variable on the same effective directive.
    * The only *pre* DAs described by OpenACC 3.0 sec. 2.6.1
      "Variables with Predetermined Data Attributes" are:
        * *pre* `private` for locally declared variables:
            * The only *exp* DAs that could refer to them would be on
              directives nested within the scope of the variable
              declarations, and those cannot expand the visibility of
              the variables, so conflicts with *pre* `private` don't
              seem possible.
        * *pre* `private` for loop control variables:
            * On a non-combined `acc loop`, the only supported *exp*
              DAs are *exp* `private` and *exp* `reduction`, and so
              the latter is the only possible conflict with *pre*
              `private`:
                * However, as discussed under "Loop Control Variables"
                  below, Clacc does not permit *exp* `reduction` for
                  loop control variables generally.  This is true
                  whether Clacc considers the loop control variable to
                  be *pre* `private` or *imp* `shared`.  Thus, this
                  restriction is not derived from *pre*, and so, under
                  Clacc, *pre* has no significance on a non-combined
                  `acc loop`.
                * Under OpenACC 3.0, no such restriction is specified,
                  so *pre* `private` could be viewed as conflicting
                  with *exp* `reduction`.
            * On a combined directive:
                * For the same reason as on a non-combined `acc loop`,
                  the restriction against *exp* `reduction` for a loop
                  control variable is not derived from *pre* `private`
                  under Clacc.
                * All *exp* DAs other than `private` and `reduction`
                  could be viewed as conflicting with *pre* `private`
                  except that they all apply to the effective compute
                  construct while *pre* `private` applies to the
                  effective loop construct:
                    * Thus, under OpenACC 3.0, they might not be
                      viewed as conflicting.
                    * Nevertheless, Clacc views them as conflicting
                      for consistency with its handling of *exp*
                      `private` on a combined directive, as discussed
                      above.
    * In summary:
        * Under OpenACC 3.0, the only way to draw a distinction
          between *pre* and *imp* is likely the conflict between a
          *pre* `private` for a loop control variable and an *exp*
          `reduction` on either a non-combined `acc loop` or a
          combined directive.
        * Under Clacc, the only way to draw a distinction between
          *pre* and *imp* is likely the conflict between a *pre*
          `private` for a loop control variable and any *exp* data
          clause other than `private` or `reduction` on a combined
          directive.

### Reductions ###

* If *exp* `reduction(`*o*`:`*v*`)` on an `acc loop`, and if *v* is
  gang-private, then:
    * If the loop is sequential, the reduction is trivial.
    * If the loop is gang-partitioned, the specified gang reduction is
      a trivial reduction per gang.
    * Notes:
        * Text to clarify that such reductions are trivial has been
          proposed for inclusion in the OpenACC spec after 2.7.
        * In the case of a trivial gang reduction, there can still be
          a non-trivial worker or vector reduction if the loop is also
          worker-partitioned or vector-partitioned.
        * A trivial reduction reduces across only one thread.  Thus,
          the reduction specifies the creation of a single private
          copy of *v* that is initialized and later merged back to the
          original *v* according *o*.  The only way that behavior
          appears to be different than just discarding the reduction
          is if either (1) the loop body performs an operation on *v*
          that's inconsistent with *o*, or (2) there's a race on
          writes to the original *v* that's somehow avoided when
          postponing the write to the exit of the loop.  Clacc makes
          the assumption that these are likely broken use cases and
          need not be supported.  Thus, Clacc implements these trivial
          reductions by simply discarding them in the translation to
          OpenMP.
* If *exp* `reduction(`*o*`:`*v*`)` on an `acc loop`, and if *v* is
  gang-shared, then *imp* `reduction(`*o*`:`*v*`)` on the parent `acc
  parallel`.  Notes:
    * Thus, Clacc handles a loop reduction for a gang-shared variable
      as a gang reduction even if the loop is not gang-partitioned and
      even if the loop is sequential.  This subtle behavior comes from
      a strict reading of the spec since OpenACC 1.0.  Text to make
      this behavior clearer has been proposed for inclusion in the
      OpenACC spec after 2.7.
    * Clacc interprets this gang reduction as an *imp* `reduction` on
      the `acc parallel` to facilitate the translation to OpenMP (for
      example, reductions cannot be specified on `omp distribute` but
      can be specified on `omp target teams`).  All references to *v*
      within the `acc parallel` then refer to gang-private copies of
      *v*.  However, under OpenACC 2.7 (and earlier), all references
      to *v* within the `acc parallel` should still refer to the
      original gang-shared *v* instead.  Text to specify that accesses
      to the original gang-shared variable are undefined throughout
      the `acc parallel` has been proposed for inclusion in the
      OpenACC spec after 2.7.  In that case, either interpretation is
      conforming.
* If *exp* `reduction(`*o*`:`*v*`)` on an `acc loop`, and if the loop
  is gang-partitioned, then *imp* `copy(`*v*`)` on the parent `acc
  parallel` overriding any *imp* `firstprivate(`*v*`)` as long as all
  of the following conditions hold:
    * *not* `copy(`*v*`)`, *not* `copyin(`*v*`)`, *not*
      `copyout(`*v*`)`, *not* `firstprivate(`*v*`)`, *not*
      `private(`*v*`)`, and *not* `reduction(`*o'*`:`*v*`)`, on that
      `acc parallel` and on any `acc loop` nested between it and the
      gang-partitioned `acc loop`.
    * There is no local declaration of *v* nested between the `acc
      parallel` and the gang-partitioned `acc loop`.
    * Notes:
        * By converting *v* from gang-private to gang-shared, this
          rule can trigger the previous rule to convert a trivial gang
          reduction to *imp* `reduction` on the `acc parallel`.
        * This rule does not follow OpenACC 2.7.  However, in our
          experiments so far, both gcc 7.3.0 and pgcc 18.10-0 appear
          to perform gang reductions and copy the reduction variable's
          values to and from the device as specified by this rule.
          This is true even when, without this rule, the reduction
          variable should be *imp* `firstprivate`.
        * There is discussion among the OpenACC technical committee
          about adding a rule like this one to the OpenACC spec after
          2.7.  However, every proposal considered so far produces
          surprising or non-portable behavior in some cases, so the
          future of this behavior is unclear.
* It is an error if, on a particular OpenACC directive, there exist
  multiple *imp|exp* `reduction` with different reduction operators
  for a single variable *v*.  Moreover, *imp* `reduction` is included
  when applying OpenACC 2.7 sec. 2.9.11 L1580-1581.  Notes:
    * That passage specifies this restriction for *exp* `reduction` on
      nested constructs, but it doesn't discuss the case where sibling
      `acc loop` constructs specify conflicting gang reductions or
      where multiple conflicting reductions appear on the same
      directive.
* Variable type restrictions for `reduction` are specified in
  `README-OpenACC-status.md` as that is a highly user-visible issue.

### Integer Expression Arguments ###

* It is an error if an argument to `num_gangs`, `num_workers`, or
  `vector_length` is not a positive integer expression.  If the
  argument to `vector_length` is not also a constant expression, Clacc
  does not use it and reports a warning diagnostic.  See
  `README-OpenACC-status.md` for rationale.

### Loop Control Variables ###

* For an `acc loop` directive with *exp* `seq` such that the loop
  control variable is just assigned instead of declared in the init of
  the attached `for` loop, the loop control variable is *imp*
  `shared`.  Notes:
    * Otherwise, there appears to be no way to tell an aggressive
      OpenACC compiler to leave such a loop as a normal sequential
      loop in C, where the variable would normally have `shared`
      semantics in that its final value is visible after the loop.
    * OpenACC 3.0 sec. 2.6.1 L1038-1039 only requires that the
      variable is private to each thread executing the loop.  Only one
      thread executes a sequential loop, and it's the same thread that
      executes outside the loop.  The specification does not appear to
      clarify whether the variable's privacy is also limited to the
      loop's region.  Clacc uses the interpretation that, as explained
      above, seems more useful.
    * In our experiments, this choice is consistent with pgcc 19.4-0,
      but gcc 8.3.0 assumes *pre* `private` instead.
    * Clacc chooses *imp* instead of *pre* for this data attribute so
      that it can be overridden by *exp* `private`.  When the loop
      control variable is *exp* `private`, it is still private to the
      one thread executing the loop, so the *exp* `private` doesn't
      conflict with the predetermined privacy described by the spec,
      so it should be permitted according to OpenACC 3.0 sec. 2.6
      L1023-1024.
* For any other `acc loop` directive, the loop control variable is
  *pre* `private`.  Notes:
    * OpenACC 2.7 sec. 2.6.1 L876-879 only requires that the variable
      is private to each thread executing the loop.  Clacc interprets
      this as *pre* `private`, which additionally means none of those
      private variables are visible after the loop.
    * This choice is not consistent with the previous case.  However,
      because the deciding factors are the presence of *exp* `seq` and
      whether the loop control variable is declared or just assigned,
      it is straight-forward for the OpenACC programmer to determine
      the visibility of the loop control variable without, for
      example, predicting the compiler's parallelization decisions.
    * In our experiments, this choice is consistent with gcc 8.3.0.
      However, pgcc 19.4-0 appears to let each thread (within each
      gang within each worker) retain the value it would have after
      incrementing once past only the iterations it performs, so the
      value visible afterward depends on the exact partitioning and
      which thread is the master and thus continues to run after the
      loop.  Thus, pgcc seems the most consistent with the exact
      wording in the spec.
    * This choice is consistent with OpenMP 4.5's choice for
      `distribute` (`gang`) and `parallel for` (`worker`)
      (sec. 2.15.1.1 p. 179 lines 24-25).
    * This choice is not consistent with OpenMP 4.5's choice for
      `simd` (`vector`) (sec. 2.15.1.1 p. 179 lines 26-27), which
      instead specifies pre `linear`, which has `lastprivate`-like
      semantics.
    * This choice is reasonably straight-forward to translate to
      OpenMP, but the pgcc approach would be harder to translate to
      OpenMP.  For example, in our experiments, `lastprivate` produces
      either the original value from before the loop or the value
      after the entire loop and not the value after only the
      iterations performed by the thread.
    * It is not clear whether the values produced by the pgcc approach
      are actually useful given their dependence on the exact
      partitioning chosen by the compiler.
* For any `acc loop` directive, *exp* `reduction` is not permitted on
  a loop control variable regardless of its data attributes.  Notes:
    * For consistency with parallelized `acc loop` directives, this
      rule applies for sequential `acc loop` directives even
      though the mapping for them discards the `reduction`.
    * If the loop control variable is declared instead of just
      assigned in the init of the attached `for` loop, any reference
      to the variable's name in the directive's clauses refers to a
      different variable, so this rule does not apply.
    * Clang's OpenMP implementation also enforces this constraint.
      That makes sense by the OpenMP spec because an OpenMP
      `reduction` is a data sharing attribute and a loop control
      variable has a different predetermined data sharing attribute.
    * For OpenACC, gcc 7.2.0 also enforces this constraint, but pgcc
      18.4-0 does not enforce it.

### Implicit Gang Clauses ###

The OpenACC technical committee has discussed [clarifying the behavior
of *naked* loop
directives](https://github.com/OpenACC/openacc-spec/issues/125).  In
these discussions, a naked loop directive is an `acc loop` directive
with *not* `seq`, *not* `gang`, *not* `worker`, and *not* `vector`.
The problem is that the OpenACC spec implies that such a loop should
run in gang-redundant mode, but existing OpenACC compilers (GCC and
PGI) usually gang-partition it.  The difference between these modes is
often important to semantic correctness besides just performance, and
understandably some existing OpenACC programs were written to expect
the semantics that existing compilers provide.  This issue has not yet
been resolved as of OpenACC 2.7.

Clacc attempts to mimic the behavior of existing OpenACC compilers by
adding *imp* `gang` to `acc loop` directives, but many questions
remain about exactly how *imp* `gang` placement should be computed.
Currently, it works as follows in Clacc:

* Any conversion of `acc loop` constructs with *exp* `auto` to
  sequential loops is performed before computing *imp* `gang`
  placement.  Notes:
    * Currently, Clacc converts all `acc loop` constructs with *exp*
      `auto` to sequential loops.  Obviously, as Clacc grows a
      descriptive interpretation of `auto`, some such constructs will
      be handled as if they have *imp* `independent` instead.
    * Performing `auto` conversions first so that *imp* `gang`
      placement depends on them places more optimization power in the
      hands of the compiler.  For example, in an `acc loop auto` nest,
      the compiler could choose any loop level for gang partitioning.
      However, the difference between gang-partitioned mode and
      gang-redundant mode can have an important impact on the
      semantics of a program.  The OpenACC programmer specified `auto`
      presumably because he cannot predict the outcome of `auto`
      conversions, and thus now he cannot predict at which of the many
      loop levels these semantics will shift.
    * Performing *imp* `gang` placement first so it does not depend on
      the outcome of `auto` conversions can reduce the possible
      semantics of an OpenACC program.  In the `acc loop auto` nest
      example, the loop nest would be either entirely gang-redundant
      or entirely gang-partitioned.
    * TODO: In our experiments so far, we have not been able to
      determine what approach pgcc 19.4-0 follows generally, and it's
      not clear what's really better here.  As the OpenACC technical
      committee standardizes an approach, we will adjust Clacc.
* Within that context, an `acc loop` construct has *imp* `gang` if all
  of the following are true:
    * *not* `gang`, *not* `worker`, and *not* `vector`.  Notes:
        * The goal here is to give the OpenACC programmer some means
          to specify partitioning exactly as he sees fit.
        * Interestingly, without this constraint, it would be
          impossible to specify gang-redundant mode combined with
          worker-partitioned or vector-partitioned mode.
    * *exp* `gang` would be permitted.  Notes:
        * Based on OpenACC 2.7, *exp* `gang` would not be permitted on
          any `acc loop` construct that has (a) an ancestor `acc loop`
          construct with *exp* `gang`, *exp* `worker`, or *exp*
          `vector`, (b) *exp* `seq`, or (c) a nested `acc loop`
          construct with *exp* `gang`.
        * These restrictions are relaxed a bit for *imp* `gang`
          because `auto` conversions are performed first.  For
          example, an `acc loop auto gang` that becomes a sequential
          loop prevents a nested `acc loop` from having an *exp*
          `gang` clause but not from having an *imp* `gang` clause.
          TODO: This behavior seems inconsistent.  Should we change
          it?  In general, the semantics of `auto` plus `gang` are
          still being clarified by the OpenACC technical committee.
    * There is no ancestor `acc loop` construct that is permitted to
      have *exp* `gang`.  Notes:
        * The point here is to chose the outermost construct possible.

Parallel Directives
-------------------

Clacc's current mapping of an `acc parallel` directive and its clauses
to OpenMP is as follows:

* `acc parallel` -> `omp target teams`
* Translation discards *imp* `nomap`.
* *exp*|*imp* `copy` -> *exp* `map` with a `tofrom` map type.
* *exp*|*imp* `copyin` -> *exp* `map` with a `to` map type.
* *exp*|*imp* `copyout` -> *exp* `map` with a `from` map type.
* *imp* `shared` -> *exp* `shared`
* *exp*|*imp* `reduction` -> *exp* `reduction`
* *exp*|*imp* `firstprivate` -> *exp* `firstprivate`
* *exp* `private` -> *exp* `private`
* *exp* `num_gangs` -> *exp* `num_teams`
* If *exp* `num_workers` with a non-constant-expression argument, and
  if there is a nested worker-partitioned `acc loop`, then *exp*
  `num_workers` -> wrap the `omp target teams` in a compound statement
  and declare a local `const` variable with the same type and value as
  the *exp* `num_workers` argument.
* Else if *exp* `num_workers` with a non-constant-expression argument
  that potentially has side effects, then *exp* `num_workers` -> wrap
  the `omp target teams` in a compound statement and insert a
  statement that casts the argument's expression to `void`.
* Else, translation discards *exp* `num_workers`.  Notes:
    * A constant-expression argument here might be used by a nested
      worker-partitioned `acc loop`.
* If *exp* `vector_length` with a non-constant-expression argument
  that potentially has side effects, then *exp* `vector_length` ->
  wrap the `omp target teams` in a compound statement and insert a
  statement that casts the argument's expression to `void`.  Moreover,
  report a warning diagnostic that `vector_length` is being ignored.
* Else, translation discards *exp* `vector_length`.  Notes:
    * A constant expression argument here might be used by a nested
      vector-partitioned `acc loop`, but a non-constant-expression
      argument is not (this follows "Semantic Clarifications" above).

Loop Directives
---------------

Clacc does not yet support the `acc kernels` directive or an orphaned
`acc loop` directive, so an `acc loop` directive must appear in an
`acc parallel` directive.

### Sequential Loops ###

Clacc treats an `acc loop` directive as sequential if any of the
following are true:

* *exp* `seq`
* *exp* `auto`
* *not* `gang`, *not* `worker`, *not* `vector`, and not *imp* `gang`
* Notes:
    * The latter two cases normally depend on the OpenACC compiler to
      determine the best way to parallelize the loop.  Again, Clacc
      does not yet support the necessary analyses and so depends on
      the application developer to prescribe the parallelization, so
      Clacc makes the conservative choice of a sequential loop
      instead.
    * The third case (without the other two) would certainly be the
      more straightforward case to improve because OpenACC specifies
      that the loop iterations are then required to be
      data-independent (that is, *exp*|*imp* `independent`).  This is
      a case where a simple AST-level analysis could go a long way for
      existing OpenACC applications that expect a descriptive
      interpretation: Clacc could add whichever of `worker` or
      `vector` doesn't conflict with other clauses on ancestor or
      nested loops.
    * Actually, the placement of *imp* `gang` is already a step in
      this direction.  Unlike an *imp* `worker` or *imp* `vector`,
      it's necessitated due to the shift in semantics between
      gang-redundant and gang-partitioned mode, and it will likely be
      specified more exactly by the OpenACC standard in the future.
      See "Implicit Gang Clauses" above for details.

Clacc's current mapping of a sequential `acc loop` directive and its
clauses to OpenMP is as follows:

* Translation discards the `acc loop` directive and the following
  clauses or attributes:
    * *exp* `seq`, *exp* `independent`, *exp* `auto`
    * *exp* `gang`, *exp* `worker`, *exp* `vector`
    * *exp* `collapse`
    * *pre* `private` for a loop control variable that is declared in
      the init of the attached `for` loop
    * *imp* `shared`, *exp* `reduction`
    * Notes:
        * For a loop control variable that is declared in the init of
          the attached `for` loop, a private copy is already made for
          the one thread executing the loop.
        * *imp* `shared` is only for variables referenced within the
          loop but declared outside the loop, and these are already
          shared by the simple C `for` loop.
        * *exp* `reduction` for a gang-private variable is discarded
          here because it is a trivial reduction, as discussed under
          "Semantic Clarifications" above.
        * *exp* `reduction` for a gang-shared variable is discarded
          here and is implemented instead via an *imp* `reduction` on
          the `acc parallel`, as discussed under "Semantic
          Clarifications" above.
* Otherwise, *exp*|*pre* `private` -> wrap the loop in a compound
  statement and declare an uninitialized local copy of the variable.
  Notes:
    * exp `private` just needs to be local to the one thread executing
      the loop, and so creating a new local variable is sufficient.

A sequential `acc loop` directive is gang-redundant, worker-single,
vector-single mode.  Thus, as far as partitioning is concerned, simple
C `for` loops are sufficient.  We considered mapping instead to
various OpenMP directives so that `private` and `reduction` clauses
could simply be translated to OpenMP clauses.  To understand the
desired properties of the chosen mapping described above, it's
important to understand why each of those considered mappings would
fail to behave correctly:

* `omp parallel for num_threads(1)` does not behave as a sequential
  loop in at least two ways:
    * It makes the loop control variable *pre* `private`, but that's
      not how Clacc treats an `acc loop seq` directive's loop control
      variable that is assigned but not declared in the init of the
      attached `for` loop.
    * When the loop control variable is modified in the body of the
      loop, behavior is not defined because the init, cond, and incr
      expressions alone must determine the number of iterations.  In
      our experiments, the current Clang OpenMP implementation
      observes only those expressions and ignores even the simplest
      modification in the body.  OpenACC 2.7 sec. 2.9 L1438-1439
      describes the related OpenACC requirement, which does not apply
      in the case of `seq`, so the mapping shouldn't impose this
      restriction.
* `omp parallel num_threads(1)` (drops the `for` from the above
  directive) avoids the above problems.  However, for either mapping,
  `acc loop seq` couldn't enclose an `acc loop gang` or be nested
  within an `acc loop vector` because `omp parallel` cannot enclose an
  `omp distribute` or be nested within an `omp simd`.

### Parallelized Loops ###

If Clacc does not treat an `acc loop` directive as sequential as
described in the previous section, then it treats it as parallelized.
In that case, Clacc's current mapping of the `acc loop` directive and
its clauses to OpenMP is as follows:

* `acc loop` -> `omp`
* *exp*|*imp* `gang` -> `distribute`
* *exp* `worker` -> `parallel for`
* If neither this nor any ancestor `acc loop` is gang-partitioned or
  worker-partitioned, then -> `parallel for` and -> *exp*
  `num_threads(1)`.  Notes:
    * We add `parallel for` for this case because OpenMP does not
      permit `omp simd` directly inside `omp target teams`.
    * An alternative might be to translate to `omp simd` directly
      inside `omp parallel`, but OpenMP does not have a combined `omp
      parallel simd` directive, leading us to question the semantics.
* *exp* `vector` -> `simd`
* The output `distribute`, `parallel for`, and `simd` OpenMP directive
  components are sorted in the above order before all clauses,
  including the above `num_threads(1)`, regardless of the input clause
  order.
* If *exp* `worker`, then *exp* `num_workers` from ancestor `acc
  parallel` -> *exp* `num_threads` where the argument is either (1)
  the original *exp* `num_workers` argument if it is a constant
  expression or (2) otherwise an expression containing only a
  reference to the local `const` variable generated for that *exp*
  `num_workers`.  Notes:
    * For the ancestor `acc parallel` and for all OpenACC directives
      nested between it and this `acc loop`, Clacc leaves the OpenMP
      data sharing attribute for the local `const` variable for
      `num_workers` as implicit.  Because the variable is `const`,
      private copies are not useful, so sharing is probably most
      efficient, but not all OpenMP directives permit an *exp*
      `shared` clause.  Thus, relying on implicit data sharing
      attributes throughout simplifies the implementation.
* If *exp* `vector`, then *exp* `vector_length` with a
  constant-expression argument from ancestor `acc parallel` -> *exp*
  `simdlen`.
* `collapse` -> `collapse`
* If *exp* `worker` or if this and every ancestor `acc loop` until the
  ancestor `acc parallel` is not gang-partitioned and not
  worker-partitioned, then *imp* `shared` -> *exp* `shared`.
* Else, *imp* `shared` -> *imp* `shared`.  Notes:
    * This case must map to *imp* `shared` because `omp distribute` or
      `omp simd` without `parallel for` (which Clacc adds for `worker`
      or to be able to nest `omp simd` directly within `omp target
      teams`) does not support a `shared` clause, so we must rely on
      OpenMP implicit data sharing rules then.
* *pre* `private` for a loop control variable that is declared in the
  init of the attached `for` loop -> *pre* `private`.  Notes:
    * Mapping to *exp* `private` would be erroneous because it would
      refer to a variable from the enclosing scope.
* If *exp* `vector` and the loop control variable is just assigned
  instead of declared in the init of the attached `for` loop, then
  *exp*|*pre* `private` for that variable -> *pre* `linear`.  Then,
  wrap the `omp simd` in a compound statement, and declare an
  uninitialized local copy of the loop control variable.  Notes:
    * For `omp simd`, OpenMP 4.5 specifies *pre* `linear` here
      (sec. 2.15.1.1 p. 179 lines 26-27), so we cannot translate to
      *exp* `private`.
    * Clacc doesn't attempt to map to *exp* `linear` because (1) the
      OpenMP spec says the step must be the increment from the
      attached loop, (2) the OpenMP spec says the default step for an
      *exp* `linear` is 1, and (3) we don't want to have to implement
      extracting the increment from the attached loop when we can just
      rely on the behavior of *pre* `linear` and thus on Clang's or
      some other target compiler's OpenMP implementation to extract it
      for us.
* In all other cases, *exp*|*pre* `private` -> *exp* `private`.
* If *exp* `worker` or *exp* `vector`, then *exp* `reduction` -> *exp*
  `reduction`.
* Else, translation discards *exp* `reduction`.  Notes:
    * *exp* `reduction` for a gang-private variable is discarded here
      because it is a trivial gang reduction, as discussed under
      "Semantic Clarifications" above.
    * *exp* `reduction` for a gang-shared variable is discarded here
      and is implemented instead via an *imp* `reduction` on the `acc
      parallel`, as discussed under "Semantic Clarifications" above.

Combined Directives
-------------------

The only combined OpenACC directive Clacc supports so far is `acc
parallel loop`, which is translated in two stages:

* **Translate from the combined OpenACC directive to effective
  separate directives**: Clacc performs this stage during the parse
  while constructing the `acc parallel loop` directive's AST node.
  Clacc builds the effective AST subtree containing the `acc parallel`
  and `acc loop` directives, and then it records the AST subtree for
  the outermost of those directives, `acc parallel`, as a hidden
  subtree of the `acc parallel loop` node.  The associated code block
  for the `acc parallel loop` node is recorded like a normal AST child
  for each of the `acc parallel loop` node and the `acc loop` node.
* **Translate from effective separate directives to OpenMP
  directives**: This stage is performed by `TransformACCToOMP` just as
  it normally would be for the separate directives.  That is, the `acc
  parallel loop` node delegates to the `acc parallel` node.

The relationship between the `acc parallel loop` node and the `acc
parallel` node is similar to the relationship between any non-combined
OpenACC directive's node and its OpenMP node.  Moreover, it
effectively replaces that relationship.  That is, most AST traversals,
including `-ast-print`, visit the `acc parallel loop` node and skip
over the hidden subtree for its effective `acc parallel` directive
because the `acc parallel loop` node without the `acc parallel`
subtree represents the original source.  The `-ast-dump` facility
prints the `acc parallel` node as a specially marked child node, which
prints its OpenMP node as a specially marked child node.  For codegen
to LLVM IR, the `acc parallel loop` node delegates to its effective
`acc parallel` node, which delegates to its OpenMP node.

Because the second stage of translation above is delegated to the
effective `acc parallel` directive, `acc parallel loop` does not
require a mapping to OpenMP.  However, it and its clauses do require a
mapping to its effective directives for the sake of the first stage,
as follows:

* `acc parallel loop` -> `acc parallel`, whose associated code block
  is an `acc loop`, whose associated code block is the associated code
  block from the `acc parallel loop`.
* *exp* `private` -> *exp* `private` on the effective `acc loop`.
* *exp* `reduction` -> *exp* `reduction` on the effective `acc loop`.
* Each remaining explicit clause is permitted on only one of the
  separate OpenACC directives, and so it is mapped to that directive.
* Predetermined and implicit attributes do not require a mapping to
  the effective directives because there are none because semantic
  analysis computes them only on the effective directives.

Potentially Unmappable Features
-------------------------------

It might prove to be impossible to map some OpenACC features to
standard OpenMP.  For such features, our plan is to map to OpenMP
language or runtime extensions, which we will implement as necessary.

When source-to-source translation (as opposed to normal full
compilation) is enabled, we will implement diagnostics to identify
uses of such features unless those diagnostics are inexact and prove
to have too many false positives.  In the worst cases, we would
identify such features at run time.

The following is a list of OpenACC features we have identified that
might not be possible to map to OpenMP, but we are still investigating
possible solutions:

* `vector_length` with a non-constant-expression argument because
  `simdlen`, to which `vector_length` is translated, requires a
  constant expression.  In the future, Clacc might support alternative
  mappings for partitioning types, either configured by the user or
  computed automatically.  If `acc loop vector` were mapped to `omp
  parallel for`, `vector_length` with a non-constant-expression
  argument would be possible.
* A gang reduction specified on an orphaned `acc loop` directive
  because the enclosing compute construct to which the reduction would
  normally be applied during translation is not statically visible.  A
  restriction against this case already appears in OpenACC 2.7 (and
  earlier), but it does not include the case of a gang reduction for a
  gang-shared variable on a non-gang loop.  Text has been proposed for
  inclusion in the OpenACC spec after 2.7 to clarify.
* Orphaned `acc loop` directive that observes `num_workers` and
  `vector_length` because the enclosing compute construct from which
  those clauses would normally be applied during translation is not
  statically visible.
* Subarrays specifying non-contiguous blocks in dynamic
  multidimensional arrays because these cannot be mapped to OpenMP
  array sections.  Notes:
    * OpenACC 2.7 sec. 2.7.1 L1108-1109 permits such subarrays.
    * OpenMP 5.0 sec. 2.9.7.1 p. 322 L3 does not permit such array
      sections in `map` clauses.
* Non-constant integer expressions in subarrays on gang-shared
  variables in `reduction` clauses on `acc loop` constructs because
  those clauses must be copied to the parent `acc parallel` (or rather
  the `omp target teams`) but the expressions might evaluate to
  different values there.
* Subarrays in `firstprivate` and `private` clauses because OpenMP
  does not permit array sections in those clauses.  See "Semantic
  Clarifications" above for details.
* Multiple reference counters because OpenMP has just one reference
  counter.

C++ Issues
----------

* Restrictions for private and reduction clauses related to
  const-qualified types could be relaxed in the case of mutable
  fields.  The OpenMP implementation does this, as hinted by OpenMP
  5.0 sec. 2.19.1.1 phrase "with no mutable members".

OpenACC Profiling Interface
===========================

Clacc's support for the OpenACC Profiling Interface is currently an
early prototype.  It is designed as a wrapper around OpenMP's OMPT.
Currently, it has been tested with an extended version of LLVM's
implementation of OMPT.

Background
----------

The OpenACC Profiling Interface is an interface between an OpenACC
runtime and an OpenACC profiling library that can be used to profile
an OpenACC application.  An OpenACC implementation, such as Clacc, is
responsible for providing the OpenACC compiler and the OpenACC
runtime.  The user of that implementation is responsible for providing
the OpenACC profiling library and the OpenACC application.

The user compiles his OpenACC application using the OpenACC compiler.
However, he can use any standard compiler to compile his OpenACC
profiling library as it is not intended to employ OpenACC directives.
The user then links his compiled OpenACC application, his compiled
OpenACC profiling library, and the provided OpenACC runtime.  This
linking step might be static or dynamic, and it might be replaced with
dynamic loading.  For simplicity in this document, we always refer to
this step as linking.

The OpenACC Profiling Interface defines OpenACC event types,
signatures for callback functions to respond to those event types, and
a callback registration interface.  The user's OpenACC profiling
library is responsible for implementing such callback functions and
registering them for relevant event types.  The OpenACC runtime is
responsible for receiving these registrations and, when an OpenACC
event type occurs during the OpenACC application's execution, calling
the registered callback function and passing the profiling data
required by its function signature.

See chapter 5 "Profiling Interface" of OpenACC 2.7 for further
details.

OMPT is similar to the OpenACC Profiling Interface such that the
analogues of an OpenACC runtime, OpenACC profiling library, and
OpenACC application are an OpenMP runtime, OMPT tool, and OpenMP
application.  See chapter 4 "OMPT Interface" of OpenMP 5.0 for further
details.

Objectives
----------

There are several profiling use cases that might come to mind when
considering that the Clacc compiler translates OpenACC to OpenMP.
It's important to be clear about which use cases Clacc supports.  In
short, Clacc enables OpenACC applications to be profiled using either
OpenACC profiling libraries or OMPT tools.  The rest of this section
explains the importance of these use cases and how, at a high level,
Clacc enables them.  The remaining sections focus on Clacc's support
for OpenACC profiling libraries.

A traditional OpenACC runtime, such as the runtime provided by PGI, is
not useful when an OpenACC application is compiled by the Clacc
compiler.  The reason is that the Clacc compiler, whether in
traditional mode or source-to-source mode, always translates OpenACC
applications to OpenMP.  Thus, an OpenMP runtime instead is required
to execute the application.  This requirement is a deliberate part of
Clacc's strategy to reuse rather than duplicate the capabilities of
OpenMP implementations, in particular the one provided by Clang and
LLVM.

To profile an OpenACC application using an OMPT tool, Clacc's OpenACC
Profiling Interface support is irrelevant.  That is, because the Clacc
compiler translates OpenACC directives to OpenMP, compilation with the
Clacc compiler is sufficient to enable profiling an OpenACC
application using an OMPT tool.  This use case may be worthwhile for
taking advantage of existing OMPT tools, for users desiring to analyze
how their OpenACC application interacts with an OpenMP runtime, and
for users desiring to migrate an application from OpenACC to OpenMP.
However, this use case is not helpful for taking advantage of existing
OpenACC profiling libraries.  Moreover, being forced to work with or
develop OMPT tools instead of OpenACC profiling libraries may be
confusing for OpenACC developers.

Clacc's OpenACC Profiling Interface support is designed to enable any
OpenACC profiling library to profile any OpenACC application
specifically when the latter is compiled by the Clacc compiler.
Again, an OpenMP runtime is required to execute the application in
this case, so Clacc's OpenACC Profiling Interface support is designed
as a wrapper around the OMPT support provided by OpenMP runtimes.
This design follows the aforementioned strategy to reuse rather than
duplicate the capabilities of OpenMP implementations.

In theory, this design does not require the original application to be
OpenACC.  That is, Clacc's OpenACC Profiling Interface support should
also enable any OpenACC profiling library to profile any OpenMP
application.  However, this is not a use case we are currently
investigating.  Moreover, our estimation at this point is that the
OpenACC Profiling Interface lacks many features desirable for
profiling OpenMP applications.

Clacc offers no support for translating OpenACC profiling libraries
into OMPT tools at the level of their source code.  That is, the Clacc
compiler translates OpenACC directives within OpenACC applications,
but it does not process any part of the OpenACC Profiling Interface
within OpenACC profiling libraries, which are not written using
directives.  Clacc's OpenACC Profiling Interface support is currently
implemented fully at the level of the runtime.

Design
------

Clacc's OpenACC Profiling Interface support is implemented in Clacc's
OpenACC runtime.  It enables OpenACC profiling libraries to profile
OpenACC applications compiled by the Clacc compiler as follows:

* The user compiles his OpenACC application to binary form using
  either (1) the Clacc compiler in traditional compilation mode or (2)
  the Clacc compiler in source-to-source mode followed by compilation
  to binary form using any OpenMP compiler.
* The user compiles his OpenACC profiling library to binary form using
  any standard compiler.  The Clacc compiler can be used if desired
  here but is not required as no OpenACC directives should be
  involved.
* The user links together his compiled OpenACC application, his
  compiled OpenACC profiling library, an OpenMP runtime that
  implements the OMPT interface, and Clacc's OpenACC runtime.
* At run time, Clacc's OpenACC runtime receives OpenACC callback
  registrations for OpenACC events from the user's OpenACC profiling
  library.  It then registers the necessary OMPT callbacks for related
  OMPT events with the OpenMP runtime.
* OMPT callback functions that Clacc's OpenACC runtime registers are
  implemented within Clacc's OpenACC runtime.  These functions
  translate the profiling data they receive into the profiling data
  required for OpenACC callbacks.  They then call the required OpenACC
  callback functions.

### OMPT Limitations ###

It is possible that Clacc's OpenACC Profiling Interface support might
one day be compatible with any OpenMP runtime that fully supports
OMPT.  However, the OpenMP 5.0 specification for OMPT would have to be
extended for this to be true.  First, some events specified by the
OpenACC Profiling Interface in OpenACC 2.7 do not correspond to events
specified by OMPT.  Second, some profiling data specified by the
OpenACC Profiling Interface cannot be obtained via callbacks currently
specified by OMPT.

Furthermore, upstream LLVM's OpenMP runtime support for OMPT is
currently incomplete, specifically omitting components related to
device offloading, which are the focus of the OpenACC Profiling
Interface.  Of the OMPT callbacks that are required by Clacc, there is
only one that is currently implemented in the upstream LLVM OpenMP
runtime: the `finalize` callback set by `ompt_start_tool`.  For Clacc,
we have prototyped support for all other required OMPT callbacks,
which are listed in the next section.  These extensions are in a very
early stage of development and are not ready to be submitted to
upstream LLVM.  In some cases, we have taken short cuts that may make
sense only in the context of Clacc.

In summary, Clacc's OpenACC Profiling Interface currently depends on
extensions to both the upstream LLVM OpenMP runtime and to OMPT
itself.  These issues represent opportunities to contribute back to
LLVM and to the OpenMP specification.

### OpenACC to OpenMP Mapping ###

The following table shows, for each OpenACC event for which an OpenACC
profiling library registers a callback, the OMPT callbacks that are
registered by Clacc's OpenACC Profiling Interface support.  This
mapping is expected to be sufficient only for the OpenACC directives
and clauses currently supported by the Clacc compiler, and so some
OpenACC events are not yet implemented, as indicated in the table.
OMPT callbacks that we devised for Clacc's OpenACC Profiling Interface
support and that are not specified by OpenMP 5.0 are shown in
**bold**.

| OpenACC Event                     | Triggering OMPT Callback                                                     | Auxiliary OMPT Callback                  |
|:----------------------------------|:-----------------------------------------------------------------------------|:-----------------------------------------|
| `acc_ev_device_init_start`        | **`ompt_callback_device_initialize_start`**                                  |                                          |
| `acc_ev_device_init_end`          | `ompt_callback_device_initialize`                                            |                                          |
| `acc_ev_device_shutdown_start`    | **`ompt_callback_device_finalize_start`**                                    |                                          |
| `acc_ev_device_shutdown_end`      | `ompt_callback_device_finalize`                                              |                                          |
| `acc_ev_runtime_shutdown`         | `finalize` set by `ompt_start_tool`                                          |                                          |
| `acc_ev_create`                   | `ompt_callback_target_data_op(optype=ompt_target_data_associate)`            |                                          |
| `acc_ev_delete`                   | `ompt_callback_target_data_op(optype=ompt_target_data_disassociate)`         |                                          |
| `acc_ev_alloc`                    | `ompt_callback_target_data_op(optype=ompt_target_data_alloc)`                |                                          |
| `acc_ev_free`                     | `ompt_callback_target_data_op(optype=ompt_target_data_delete)`               |                                          |
| `acc_ev_enter_data_start`         | **`ompt_callback_target_map_start`**                                         | `ompt_callback_target(kind=ompt_target)` |
| `acc_ev_enter_data_end`           | `ompt_callback_target_map`                                                   | `ompt_callback_target(kind=ompt_target)` |
| `acc_ev_exit_data_start`          | **`ompt_callback_target_map_exit_start`**                                    | `ompt_callback_target(kind=ompt_target)` |
| `acc_ev_exit_data_end`            | **`ompt_callback_target_map_exit_end`**                                      | `ompt_callback_target(kind=ompt_target)` |
| `acc_ev_update_start`             | *unimplemented*                                                              |                                          |
| `acc_ev_update_end`               | *unimplemented*                                                              |                                          |
| `acc_ev_compute_construct_start`  | `ompt_callback_target(kind=ompt_target, endpoint=ompt_scope_begin)`          |                                          |
| `acc_ev_compute_construct_end`    | `ompt_callback_target(kind=ompt_target, endpoint=ompt_scope_end)`            |                                          |
| `acc_ev_enqueue_launch_start`     | `ompt_callback_target_submit`                                                | `ompt_callback_target(kind=ompt_target)` |
| `acc_ev_enqueue_launch_end`       | **`ompt_callback_target_submit_end`**                                        | `ompt_callback_target(kind=ompt_target)` |
| `acc_ev_enqueue_upload_start`     | `ompt_callback_target_data_op(optype=ompt_target_data_transfer_to_device)`   |                                          |
| `acc_ev_enqueue_upload_end`       | `ompt_callback_target_data_op(optype=ompt_target_data_transfer_to_device)`   |                                          |
| `acc_ev_enqueue_download_start`   | `ompt_callback_target_data_op(optype=ompt_target_data_transfer_from_device)` |                                          |
| `acc_ev_enqueue_download_end`     | `ompt_callback_target_data_op(optype=ompt_target_data_transfer_from_device)` |                                          |
| `acc_ev_wait_start`               | *unimplemented*                                                              |                                          |
| `acc_ev_wait_end`                 | *unimplemented*                                                              |                                          |

One way to conceptualize of the interaction between Clacc's OpenACC
Profiling Interface support and the OpenMP runtime is that OMPT
callbacks trigger OpenACC events.  However, as depicted above, the
mapping is not one-to-one.  For some OpenACC events, the profiling
data required for the event's callback depends on profiling data
supplied by callbacks for multiple OpenMP events.  For some OpenMP
events, the profiling data supplied by the event's callback is
required by the callbacks for multiple OpenACC events.

For each OpenACC event, we use the term *triggering OMPT callback* for
the OMPT callback that actually dispatches the OpenACC callback.  We
use the term *auxiliary OMPT callback* for OMPT callbacks that merely
gather required data.  So far, the only auxiliary OMPT callback is
`ompt_callback_target`, which associates a device number with a
`target_id`, which is passed to many other OMPT callbacks associated
with the same OpenMP target region.  Sometimes, for an OMPT callback
to serve the role specified in the above table, the data passed to the
callback must meet certain conditions.  Those conditions, if any, are
shown in parentheses next to the callback name in the table.

Because an OpenACC profiling library can register and unregister
callbacks for OpenACC events throughout its execution, and because the
mapping to OpenMP callbacks is not one-to-one, Clacc maintains a
reference count for each OMPT callback to determine when it is safe to
unregister it from the OpenMP runtime.

### OMPT Callback Timing vs. Extensions ###

In some cases, the precise timing required for an OMPT event relative
to a set of related OpenMP runtime actions was not immediately obvious
to us when reading the OpenMP 5.0 specification.  This timing is
particularly important when such a set corresponds to multiple OpenACC
events but to only one OMPT event.  In that case, identifying that
timing is key to identifying what OpenACC event the OMPT event's
callback should trigger and what OMPT extension events are needed to
trigger the remaining OpenACC events.  The following list explains
Clacc's rationale for such cases:

* `ompt_callback_device_initialize`
    * OpenMP sec. 2.12.1 p. 160 L3-7:

        > The device-initialize event occurs in a thread that
        > encounters the first target, target data, or target enter
        > data construct or a device memory routine that is associated
        > with a particular target device after the thread initiates
        > initialization of OpenMP on the device and the device's
        > OpenMP initialization, which may include device-side tool
        > initialization, completes.

    * OpenMP sec. 4.5.2.19 p. 482 L24-25:

         > The OpenMP implementation invokes this callback after
         > OpenMP is initialized for the device but before execution
         > of any OpenMP construct is started on the device.

    * While the first passage above is hard to parse, combined with
      the second passage, it seems clear that this callback triggers
      after device initialization is complete.
    * Clacc's implementation of this callback thus triggers
      `acc_ev_device_init_end` instead of `acc_ev_device_init_start`.

* `ompt_callback_device_finalize`
    * OpenMP 5.0 sec. 2.12.1 p. 160 L12-13:

        > The device-finalize event for a target device that has been
        > initialized occurs in some thread before an OpenMP
        > implementation shuts down.

    * OpenMP 5.0 sec. 4.5.2.20 p. 484 L12-18:

        > A registered callback with type signature
        > ompt_callback_device_finalize_t is dispatched for a device
        > immediately prior to finalizing the device.  Prior to
        > dispatching a finalization callback for a device on which
        > tracing is active, the OpenMP implementation stops tracing
        > on the device and synchronously flushes all trace records
        > for the device that have not yet been reported. These trace
        > records are flushed through one or more buffer completion
        > callbacks with type signature
        > ompt_callback_buffer_complete_t as needed prior to the
        > dispatch of the callback with type signature
        > ompt_callback_device_finalize_t.

    * The second passage above says flushing of traces occurs "prior
      to dispatching a finalization callback", which occurs
      "immediately prior to finalizing the device".  This might imply
      that flushing of traces is prior to and not part of the
      finalization process.  Clacc assumes instead that "finalizing
      the device" really indicates the *end* of the finalization
      process, which can then be considered to include flushing of
      traces.
    * Clacc's implementation of this callback thus triggers
      `acc_ev_device_shutdown_end` instead of
      `acc_ev_device_shutdown_start`, which is logically triggered
      before flushing of traces.  (However, device traces haven't yet
      actually been implemented in LLVM's OpenMP runtime, so these
      events are actually triggered back to back at the moment.)

* `ompt_callback_target_map`
    * OpenMP 5.0 sec. 2.19.7.1 p. 321 L14:

        > The target-map event occurs when a thread maps data to or
        > from a target device.

    * OpenMP 5.0 sec. 4.5.2.27 p. 493 L12-20:

        > An instance of a target, target data, target enter data, or
        > target exit data construct may contain one or more map
        > clauses. An OpenMP implementation may report the set of
        > mappings associated with map clauses for a construct with a
        > single ompt_callback_target_map callback to report the
        > effect of all mappings or multiple ompt_callback_target_map
        > callbacks with each reporting a subset of the
        > mappings. Furthermore, an OpenMP implementation may omit
        > mappings that it determines are unnecessary. If an OpenMP
        > implementation issues multiple ompt_callback_target_map
        > callbacks, these callbacks may be interleaved with
        > ompt_callback_target_data_op callbacks used to report data
        > operations associated with the mappings.

    * Based on the word "when" in the first passage, Clacc's
      implementation of this callback should trigger either
      `acc_ev_enter_data_start` or `acc_ev_enter_data_end` instead of
      `acc_ev_exit_data_start` or `acc_ev_exit_data_end`.
    * This callback requires device addresses, so it must follow all
      associated device allocations, and logically it then follows all
      associated `ompt_callback_target_data_op` callbacks with
      `optype=ompt_target_data_alloc`.
    * Because it is meant to describe mappings, it also logically
      follows all associated `ompt_callback_target_data_op` callbacks
      with `optype=ompt_target_data_associate`.
    * Clacc's implementation of this callback thus triggers
      `acc_ev_enter_data_end` not `acc_ev_enter_data_start`.

* `ompt_callback_target_submit`
    * OpenMP 5.0 sec. 2.12.5 p. 173 L26-27:

        > The target-submit event occurs prior to creating an initial
        > task on a target device for a target region.

    * Based on the word "prior", Clacc's implementation of this
      callback triggers `acc_ev_enqueue_launch_start` not
      `acc_ev_enqueue_launch_end`.

* `ompt_callback_target_data_op(optype=ompt_target_data_transfer_to_device)`
    * OpenMP 5.0 sec. 2.19.7.1 p. 321 L15:

        > The target-data-op event occurs when a thread initiates a
        > data operation on a target device.

    * Based on the word "initiate", Clacc's implementation of this
      callback should trigger either `acc_ev_enqueue_upload_start` or
      `acc_ev_enqueue_upload_end`.  That is, this callback indicates
      when the transfer starts not when it completes.
    * Currently, the data transfer actions are synchronous in LLVM's
      OpenMP implementation (`memcpy`, `cuMemcpyHToD`, or
      `cuMemcpyDToH`) with no obvious enqueue stage.  Clacc's
      implementation of this callback thus triggers both
      `acc_ev_upload_launch_start` and `acc_ev_enqueue_upload_end`
      back to back before the data transfer.
    * If that synchronous behavior does not hold true in the future
      for all architectures, and there is an important enqueue stage
      for data transfers, it might be necessary to create an OMPT
      extension to distinguish the `acc_ev_enqueue_upload_start` and
      `acc_ev_enqueue_upload_end` events.

* `ompt_callback_target_data_op(optype=ompt_target_data_transfer_from_device)`
    * Similar to the previous callback, Clacc's implementation of this
      callback triggers `acc_ev_enqueue_download_start` and
      `acc_ev_enqueue_download_end` back to back before the data
      transfer.

OpenACC Clarifications
----------------------

There are several issues related to the interpretation of the OpenACC
specification that we need to investigate further:

* The following event types never trigger when offloading is disabled
  (that is, `-fopenmp-targets` has not been specified), but this
  behavior is questionable:
    * `acc_ev_device_init_start`, `acc_ev_device_init_end`
    * `acc_ev_device_shutdown_start`, `acc_ev_device_shutdown_end`
    * `acc_ev_enqueue_upload_start`, `acc_ev_enqueue_upload_end`
    * `acc_ev_enqueue_download_start`, `acc_ev_enqueue_download_end`
    * `acc_ev_create`, `acc_ev_delete`, `acc_ev_alloc`, `acc_ev_free`
    * `acc_ev_enter_data_start`, `acc_ev_enter_data_end`
    * `acc_ev_exit_data_start`, `acc_ev_exit_data_end`
    * Notes:
        * pgcc 19.4-0 with `-ta:multicore` has the same behavior.
        * OpenACC 2.7 does not make it clear whether these event types
          should trigger when offloading is disabled.
* The following event types are among those that do trigger when
  offloading is disabled, but this behavior is questionable:
    * `acc_ev_enqueue_launch_start`, `acc_ev_enqueue_launch_end`
    * Notes:
        * pgcc 19.4-0 with `-ta:multicore` does not have this
          behavior.
        * OpenACC 2.7 does not make it clear whether these event types
          should trigger when offloading is disabled.
* `acc_ev_{enter,exit}_data_{start,end}`,
  `acc_ev_{create,alloc,delete}`, and
  `acc_ev_enqueue_{up,down}load_{start,end}` events trigger within the
  associated `acc_ev_compute_construct_{start,end}` event pair, but
  they trigger outside them instead when using pgcc 19.4-0.  Notes:
    * Either behavior appears to be permitted according to OpenACC 2.7
      sec. 5.1.7 L2825-2827, which says, "If there are data clauses on
      the compute construct, those data clauses may be treated as part
      of the compute construct, or as part of a data construct
      containing the compute construct."
    * We need to check more recent pgcc and discuss with the OpenACC
      technical committee.
* `acc_ev_create` triggers before the associated `acc_ev_alloc`, but
  they trigger in the reverse order when using pgcc 19.4-0.  Notes:
    * OpenACC 2.7 sec. 5.1.4 L2800-2802 says "An `acc_ev_create` event
      may be preceded by an `acc_ev_alloc` event, if newly allocated
      memory is used for this device data, or it may not, if the
      runtime manages its own memory pool."
    * This seems to encourage the Clacc behavior.
    * It's not clear if this permits the pgcc 19.4-0 behavior.
      Perhaps the `acc_ev_alloc` events represent enlargement of the
      memory pool after `acc_ev_create` events use up bytes there.
    * We need to check more recent pgcc and discuss with the OpenACC
      technical committee.
* pgcc 19.4-0 seems to trigger `acc_ev_delete` when it should trigger
  `acc_ev_free`, which it never seems to trigger.  Notes:
    * We need to check more recent pgcc and discuss with the OpenACC
      technical committee.
* OpenACC 2.7 specifies the typedef `acc_prof_lookup_func`, but it's
  spelled `acc_prof_lookup` in pgcc 19.4-0's `acc_prof.h`.  Notes:
    * Clacc's `acc_prof.h` typedefs one to the other in order to
      support OpenACC profiling libraries written for the OpenACC
      standard or for pgcc 19.4-0.
    * We need to check a more recent pgcc, and we will raise this
      discrepancy with the OpenACC technical committee.
* The triggering of `acc_ev_runtime_shutdown` is questionable because
  it never seems to trigger when using pgcc 19.4-0.
* How should the `device_number` and source location fields of
  `acc_prof_info` and the `parent_construct` field of `acc_event_info`
  be set for `acc_ev_runtime_shutdown`?
* How should `vendor`, `device_handle`, `context_handle`, and
  `async_handle` fields of `acc_api_info` be assigned?

Limitations
-----------

Limitations left to be resolved in Clacc's OpenACC Profiling Interface
support currently include:

* `acc_prof_register` and `acc_prof_unregister` must be called only
  via the pointers obtained within `acc_register_library` and must be
  called only within `acc_register_library`.  Notes:
    * That is, `acc_prof_register` and `acc_prof_unregister` cannot be
      linked and called directly, and the pointers passed to
      `acc_register_library` are not intended to be stored and used
      after `acc_register_library`.
    * The underlying issue is that whether OMPT callbacks are desired
      must be known at the time of `ompt_start_tool`, but OMPT
      callback registrations cannot be performed until the OpenMP
      runtime performs the `initialize` callback later.  The reason is
      that, if there are no callbacks, `ompt_start_tool` should return
      null to avoid unnecessarily enabling OMPT and potentially
      impacting OpenMP performance, but it's the `initialize` callback
      that receives pointers to functions like `ompt_set_callback`.
    * Clacc addresses this issue as follows.  `acc_prof_register` and
      `acc_prof_unregister` queue their registration actions instead
      of performing them immediately.  Clacc implements
      `ompt_start_tool` to call `acc_register_library` and to return
      null if `acc_register_library` leaves the registration queue
      empty.  Otherwise, Clacc's `ompt_start_tool` returns non-null
      and specifies an `initialize` callback that later iterates the
      queue and actually performs the required callback registrations.
    * In the future, Clacc may expose `acc_prof_register` and
      `acc_prof_unregister` for use outside of `acc_register_library`.
      They would queue their registration actions until the
      `initialize` callback is dispatched, and they would perform them
      directly afterward.
    * That change would entirely eliminate this limitation except
      that, if neither `acc_prof_register` or `acc_prof_unregister` is
      called by the time the OpenMP runtime calls `ompt_start_tool`,
      OMPT would not be enabled, so calling `acc_prof_register` or
      `acc_prof_unregister` afterward would have no effect.  To
      address that use case, Clacc's `ompt_start_tool` could be
      extended to check an environment variable or weakly linked
      function that specifies whether OMPT should always be enabled.
      Thus, the question of whether to enable profiling would become a
      link-time or run-time switch external to the OpenACC application
      and profiling library code.  When called too late,
      `acc_prof_register` and `acc_prof_unregister` should also
      produce warnings or errors advising the use of such a feature.
* For each event type, at most one occurrence of one callback can be
  registered at a time, and it cannot be toggled.  Notes:
    * OMPT does not appear to have such features.
    * Eliminating this limitation requires building more sophisticated
      OpenACC Profiling Interface callback registration tables.
* The following event types are not yet supported because the Clacc
  compiler does not yet implement directives and clauses that would
  trigger them:
    * `acc_ev_update_start`, `acc_ev_update_end`
    * `acc_ev_wait_start`, `acc_ev_wait_end`
* `ACC_PROFLIB` is not yet supported.
* Some of the data passed to the OpenACC callbacks currently have
  questionable values or have been omitted:
    * The `valid_bytes` field is properly set in each of these structs
      to indicate which fields are omitted, as indicated below.
    * Information we do not know how to obtain via OMPT might require
      OMPT extensions.
    * Fields not mentioned below are expected to be correctly
      implemented.
    * `acc_prof_info`:
        * `thread_id` always seems to be set to `0` currently, so we
          might not be obtaining the value correctly.
        * `async` is always set to `acc_async_sync` because the Clacc
          compiler does not yet support the `async` clause.  Thus,
          this value appears to be correct according to OpenACC.
        * `async_queue` is thus omitted.
        * All fields describing source locations are omitted because
          we do not know how to obtain them via OMPT.
    * `acc_event_info`:
        * `tool_info` is always set to `NULL`, and data cannot yet be
          shared between `_start` and `_end` events.  This should be
          one of the easier limitations to fix, if needed.
        * `acc_data_event_info`:
            * `var_name` is always set to `NULL` because we do not
              know how to obtain it via OMPT.  Setting to `NULL` is
              permitted by OpenACC.
        * `acc_launch_event_info`:
            * `kernel_name` is always set to `NULL` because we do not
              know how to obtain it via OMPT.  Setting to `NULL` is
              permitted by OpenACC.
            * `num_gangs`, `num_workers`, and `vector_length` are
              omitted because we do not know how to obtain them via
              OMPT:
                * The problem with `num_gangs` is that OpenACC 2.7
                  says it's the number of gangs *created*, but the
                  `ompt_callback_target_submit` callback only provides
                  the number of teams *requested*.  It might possible
                  to retrieve the required data from OMPT trace
                  records, but we have not implemented that support
                  yet.
                * The problem with `num_workers` and `vector_length`
                  is that, in contrast with OpenACC compute
                  directives, `num_threads` and `simdlen` are not
                  specified at the level of an OpenMP target
                  directive.
    * `acc_api_info`:
        * `device_api` is always set to `acc_device_api_none` because
          it's used to indicate the semantics of later fields we do
          not yet support.  Thus, this value appears to be correct
          according to OpenACC.
        * `vendor` is omitted because we do not know the right way to
          choose a vendor number (see "OpenACC Clarifications" above).
        * `device_handle`, `context_handle`, and `async_handle` are
          omitted because we have not yet determined how to properly
          support them (see "OpenACC Clarifications" above)
* Clacc's OpenACC Profiling Interface support is an early prototype
  and needs more thorough testing with real OpenACC applications and
  profiling libraries.  In particular, we took shortcuts in our
  extensions to LLVM's OMPT support, and there might be issues with,
  for example, thread safety.
* The source of Clacc's OpenACC Profiling Interface support is
  integrated with the source of LLVM's OpenMP runtime implementation.
  Notes:
    * The source needs to be separated into two distinct libraries
      that can be built separately.
    * This separation should facilitate continuous integration of
      upstream work into Clacc, and it should facilitate the eventual
      contribution of Clacc to upstream.
    * This separation would also be necessary to eventually enable use
      of Clacc's OpenACC Profiling Interface support with other OpenMP
      runtime implementations.
* Because Clacc's OpenACC Profiling Interface support depends on OMPT
  extensions, any OpenMP runtime implementation must support these
  same extensions to be usable.  Notes:
    * A graceful mechanism to reject registration of OpenACC event
      types for which required OMPT callbacks are not supported by the
      linked OpenMP runtime should be devised.
    * That mechanism could also handle unimplemented but standard OMPT
      callbacks.
