This document describes the current design of Clacc, which extends
Clang and LLVM with support for OpenACC.

Design Rationale
================

This document focuses on the details of the current Clacc design and
only summarizes the design rationale.  A more complete description of
the design rationale, including a presentation of several design
alternatives that were considered, appears in sections I through II.D
of the following paper:

> Clacc: Translating OpenACC to OpenMP in Clang, Joel E. Denny, Seyong
> Lee, and Jeffrey S. Vetter, 2018 IEEE/ACM 5th Workshop on the LLVM
> Compiler Infrastructure in HPC (LLVM- HPC), Dallas, TX, USA, (2018).

High-Level Design
=================

A key feature of Clacc's design is to translate OpenACC to OpenMP in
order to build on Clang's existing OpenMP compiler and runtime
support.  Clacc performs this translation at the AST level, producing
AST representations of both the original OpenACC and the generated
OpenMP.  As such, Clacc's design is depicted abstractly in the
following figure:

```
   OpenACC source
         |
         | parser
         v
    OpenACC AST
         |
         | TransformACCToOMP
         v
    OpenMP AST
         |
         | codegen
         v
      LLVM IR
         |
         | LLVM
         v
    executable
  OpenACC runtime
   OpenMP runtime
```

The components of this diagram are as follows:

* **OpenACC source** is C application source code containing OpenACC
  constructs.  C++ will be supported in the future.  Currently,
  Fortran support is not planned and would not be based on Clang.
* **Parser** is the existing Clang parser and semantic analyzer
  extended for OpenACC.
* **OpenACC AST** is a Clang AST in which OpenACC constructs are
  represented by OpenACC node types, which are a Clacc extension to
  Clang.
* **`TransformACCToOMP`** is a new Clang component introduced by Clacc
  to transform OpenACC to OpenMP entirely at the AST level.
* **OpenMP AST** is a Clang AST in which OpenACC constructs have been
  lowered to OpenMP constructs represented by OpenMP node types, which
  exist in Clang independently of Clacc.
* **Codegen** is the existing Clang backend, which lowers the OpenMP
  AST to LLVM IR.
* **LLVM IR** is the usual LLVM intermediate representation
  generated by Clang for an OpenMP AST.
* **LLVM** consists of all LLVM optimization passes and backends that
  lower LLVM IR into object form.
* **Executable** is the final application executable.
* **OpenACC runtime** is built on top of LLVM's existing **OpenMP
  runtime** with extensions for OpenACC's run-time environment
  variables, library API, etc.

This design has a number of advantages.  First, the construction of an
OpenACC AST should facilitate the development of additional OpenACC
source-level tools, such as pretty printers, static analyzers,
lint-like tools, and debugger and editor extensions.  The construction
of an OpenMP AST should facilitate a number of non-traditional
user-level compiler features, such as automated porting of OpenACC
applications to OpenMP, and reuse of existing OpenMP tools for
OpenACC.  Because the OpenACC syntax and OpenMP syntax are so similar,
simple translations from OpenACC to OpenMP are easier to implement at
the AST level than as part of a later compiler stage.  Finally,
because the AST is the highest-level representation, implementing at
the AST level maximizes the amount of the existing OpenMP
implementation that Clacc can reuse.

It is important to understand that the above description is abstract.
Specifically, as described in the next section, `TransformACCToOMP` is
not a distinct compiler phase, and the OpenACC AST and OpenMP AST are
actually represented within a single Clang AST.

TransformACCToOMP
=================

A key issue in transforming OpenACC to OpenMP in Clang ASTs is that
Clang ASTs are designed to be immutable once constructed.  This
immutability property might at first seem to make Clacc's
`TransformACCToOMP` component impossible to implement, but it does
not.  In this section, we describe Clang's `TreeTransform` facility
and explain how `TransformACCToOMP` employs it to cleanly work around
this immutability property.

Background: TreeTransform
-------------------------

Independently of Clacc, Clang uses the `TreeTransform` facility to
transform C++ templates for the sake of instantiating them.  When the
parser reaches a template instantiation in the source code,
`TreeTransform` builds a transformed copy of the AST subtree that
represents the template, and it inserts that copy into the AST.  This
insertion is part of the normal process of extending the AST during
parsing and so does not violate AST immutability.

`TreeTransform`'s design has some convenient properties for Clacc's
purposes:

* **Extensibility**: `TreeTransform` is a class template employing the
  curiously recurring template pattern (CRTP) for static polymorphism.
  Thus, it is possible to override default behavior that is reasonable
  for C++ template instantiation but not for translation from OpenACC
  to OpenMP.
* **Encapsulation of `Sema`**: `TreeTransform`'s interface serves as a
  convenient encapsulation of semantic actions that are normally
  called during parsing.  This encapsulation enables Clacc to call
  those actions to build OpenMP ASTs without developing fragile
  dependencies on the current OpenMP implementation within `Sema`.

However, there are also some caveats to consider for `TreeTransform`:

* **Transitory semantic data**: To build new nodes, `TreeTransform`
  runs many of the same semantic actions that the parser normally
  runs.  Those semantic actions require the transitory semantic data
  that has been stored in Clang's `Sema` object by the time the parser
  reaches the syntactic context where new nodes are to be inserted,
  but the parser gradually discards some of that semantic data as the
  parser progresses to other syntactic contexts.  Thus,
  `TreeTransform` cannot be run on arbitrary nodes in the AST at
  arbitrary times.  For example, to run `TreeTransform` on arbitrary
  nodes in a translation unit after the parsing of that translation
  unit has completed, it might be necessary to transform the
  translation unit's entire AST in order to rebuild all of the
  necessary transitory semantic metadata.
* **Permanent semantic data**: Currently, parsing a C++ template
  permanently associates semantic data with that template's AST
  subtree in a way that's compatible with later runs of
  `TreeTransform` for instantiations of that template.  However,
  there's no guarantee that semantic data that is reasonable for C++
  template instantiation will be compatible with any arbitrary
  extension of `TreeTransform`.  For example, we have noticed that, if
  we write a simple `TreeTransform` extension that merely duplicates
  an OpenMP region immediately after that region's node is
  constructed, the default `TreeTransform` implementation does not
  update the declaration contexts for variable declarations that are
  local to the duplicate region (see `TreeTransform::TransformDecl`),
  so those duplicate variables appear to be declared in the original
  region, resulting in spurious compiler diagnostics.
* **Redundant AST subtrees**: As described above, `TreeTransform` is
  designed to construct modified versions of existing subtrees, and it
  is not designed to remove the original subtrees.  This behavior
  makes sense for C++ template instantiation because the original
  template must remain in the AST for additional instantiations.
  Moreover, the template and its instantiations represent distinct
  regions of the original source.  However, in the case of Clacc, an
  OpenACC subtree and the OpenMP subtree to which it is translated
  represent different versions of the same region of the source, so
  AST iterations must take special care not to visit both when they're
  expecting only one version of the source.

Design
------

Clacc's `TransformACCToOMP` component is implemented as a class
derived via CRTP from `TreeTransform`.  As mentioned earlier,
`TransformACCToOMP` does not represent a distinct compiler phase.
Instead, immediately after parsing each OpenACC region and
constructing an associated OpenACC subtree, Clacc passes the OpenACC
subtree to `TransformACCToOMP` to construct the corresponding OpenMP
subtree.  Clacc adds the resulting OpenMP subtree's root as a hidden
child of the OpenACC subtree's root, and then parsing continues.

For example, consider this function written in OpenACC, where comments
show the equivalent OpenMP:

```
void foo() {
  #pragma acc parallel  // #pragma omp target teams
  #pragma acc loop gang // #pragma omp distribute
  for (int i=0; i<2; ++i)
    // loop body
}
```

The AST that Clacc constructs is depicted below:

```
       TranslationUnit
              |
         FunctionDecl
              |
         CompoundStmt
              |
     ACCParallelDirective
              |          `-OMPNode-> OMPTargetTeamsDirective
       ACCLoopDirective                         |
            /   \      `---OMPNode---> OMPDistributeDirective
ACCGangClause   ForStmt                         |
                   |                         ForStmt
                                                |
```

Thus, the `ForStmt` node and its subtree are duplicated.  The
`ACCLoopDirective` node is translated to an `OMPDistributeDirective`
node, which becomes the normal parent for the translated `ForStmt`
node and the hidden OpenMP child for the `ACCLoopDirective` node.
Finally, the `ACCParallelDirective` is translated to an
`OMPTargetTeamsDirective` node, which becomes the normal parent for
the `OMPDistributeDirective` node and the hidden OpenMP child for the
`ACCParallelDirective` node.

Clacc overcomes the `TreeTransform` caveats discussed in the previous
section as follows:

* **Transitory semantic data**: Because Clacc calls
  `TransformACCToOMP` immediately after constructing an OpenACC
  subtree, the exact transitory semantic data needed to construct the
  corresponding OpenMP subtree is present.
* **Permanent semantic data**: So far, Clacc is able to override
  specific `TreeTransform` functionality in order to transform
  semantic data that would be permanent across C++ template
  instantiation but that must be different between OpenACC and OpenMP
  subtrees.
* **Redundant AST subtrees**: AST traversals are typically based on
  Clang's `RecursiveASTVisitor` facility.  Most AST traversal
  developers and users likely expect for traversals to visit an AST
  representing the original source code only.  Because the OpenMP node
  to which an OpenACC node is translated is not recorded as a normal
  child of the OpenACC node, `RecursiveASTVisitor` visits the OpenACC
  node but skips its hidden OpenMP child.  However, while visiting an
  OpenACC node, a visitor can be written to call the node's
  `getOMPNode` member function to access the OpenMP node, possibly for
  a recursive visitation.

As a result, Clacc supports at least three kinds of AST traversals:

* **Visit OpenACC only**: For example, `-ast-print` is an existing
  Clang command-line option for translating the Clang AST back to
  source.  Because the output of `-ast-print` has thus always
  corresponded to the original preprocessed input and never a lowered
  version of it, Clacc extends it for OpenACC not to include the
  OpenMP translation.  In the previous example, `-ast-print` thus
  visits the `ACCParallelDirective` node, the `ACCLoopDirective` node,
  and the original `ForStmt` subtree but not the
  `OMPTargetTeamsDirective` node, the `OMPDistributeDirective` node,
  or the translated `ForStmt` subtree.
* **Delegate to OpenMP**: For example, one of the major motivations
  for translating the OpenACC AST to an OpenMP AST is to reuse the
  existing LLVM IR codegen implementation for OpenMP.  Thus, for LLVM
  IR codegen, each OpenACC node delegates to its hidden OpenMP child.
  In the previous example, the `ACCParallelDirective` node delegates
  LLVM IR codegen to the `OMPTargetTeamsDirective` node and its
  subtree, and the normal subtree of the `ACCParallelDirective` node
  is not visited.
* **Visit OpenACC and OpenMP**: For example, `-ast-dump` is an
  existing Clang command-line option for printing a textual
  representation of the AST structure, including parent-child
  relationships, source location information, and computed types.
  This feature is clearly designed for debugging ASTs and is very
  useful for Clang developers.  For each OpenACC AST node, Clacc
  extends this feature to always produce a full representation of that
  node's subtree including, as a specially marked child, the OpenMP
  subtree to which it translates.

Redundant AST subtrees might at first seem to be a disadvantage of
employing `TreeTransform` in `TransformACCToOMP`.  However, because it
results in a representation of the chosen mapping from OpenACC to
OpenMP, we believe it augments the potential for constructing flexible
debugging and analysis tools on top of Clacc.  The capabilities of
`-ast-dump`, as described above, and `-fopenacc-print`, as described
in the next section, are simple examples.

Codegen
=======

As mentioned in the previous section, an OpenACC AST node implements
LLVM IR codegen by delegating to its hidden OpenMP child.  The most
obvious points for this implementation are the OpenACC cases in the
main switch on AST node types within Clang codegen's
`CodeGenFunction::EmitStmt`.

While necessary, those implementation points are insufficient for
offloading support.  The trouble is that the OpenMP codegen
implementation also has a hook into Clang's codegen framework outside
that switch.  This hook calls
`CGOpenMPRuntime::scanForTargetRegionsFunctions`, which recurses
through AST nodes looking for OpenMP target regions to emit in
separate device functions.  Thus, Clacc extends this scan to look for
OpenACC AST nodes and, as before, to delegate the required codegen to
their hidden OpenMP children.

Source-to-Source Translation
============================

The `TransformACCToOMP` section described how Clacc uses Clang's
`TreeTransform` facility to construct and attach hidden OpenMP
subtrees to OpenACC subtrees.  It also mentions that `-ast-print`
prints only OpenACC.  In this section, we describe Clang's `Rewrite`
facility, which is normally used in Clang for source-to-source
translation, and we describe how Clacc prints OpenMP source.

Background: Rewrite
-------------------

The `Rewrite` facility in Clang is used in tools like `clang-format`
and `clang-tidy` to perform source-to-source translation.  However,
`Rewrite` does not perform AST transformations.  Instead, `Rewrite`
provides an API for making textual modifications to Clang's input
buffer, which contains the original input source code, while using the
Clang AST to guide those modifications.

To produce a transformed AST, the transformed source from `Rewrite`
must be parsed anew by Clang to construct an entirely separate AST.
For this reason, `Rewrite` is most useful for implementing a single
transformation pass whose output is source.  `Rewrite` is not
efficient for successive transformation passes or for LLVM IR codegen.
Direct AST transformations are better for those purposes.

Because traditional OpenACC compilation is a major use case for Clacc,
and because for Clang that requires LLVM IR codegen, we chose
`TreeTransform` not `Rewrite` to implement `TransformACCToOMP`.
However, source-to-source translation is also a Clacc use case, and,
as discussed in the next section, `Rewrite` is helpful there after
`TransformACCToOMP`.

Design
------

To enable source-to-source translation from the Clang command line,
Clacc supports two new Clang command-line options: `-fopenacc-print`,
which is built on `Rewrite`, and `-fopenacc-ast-print`, which is built
on `-ast-print`.  Each takes any of the following values:

* `acc`: OpenACC constructs are printed and the OpenMP constructs to
  which they were translated are ignored.  Thus, this value is likely
  not helpful to users but can be helpful to developers for debugging
  the Clacc implementation.  That is, `-fopenacc-print=acc` merely
  prints the original source without modification, and
  `-fopenacc-ast-print=acc` is a more convenient form of `-Xclang
  -ast-print -fsyntax-only -fopenacc`.
* `omp`: OpenMP constructs are printed, and the OpenACC constructs
  from which they were translated are ignored.
* `acc-omp`: OpenACC constructs are printed and the OpenMP constructs
  to which they were translated are printed in neighboring comments.
* `omp-acc`: OpenMP constructs are printed and the OpenACC constructs
  from which they were translated are printed in neighboring comments.

In the last two cases, Clacc will avoid duplicating the code block
associated with a directive if that code block prints identically in
both the OpenACC and OpenMP versions.  The output then looks similar
to the code passage in the previous example.

Originally, Clacc only supported the functionality of
`-fopenacc-ast-print` (but under a different name).  Because it's
built on `-ast-print`, its functionality is problematic in several
ways:

* `-ast-print` was designed for debugging and not for faithful
  printing of the AST.  Even so, we have successfully contributed
  upstream a number of fixes to improve the fidelity of its output on
  the grounds that such fixes also improve the debugging use case.
  Still, our hunch is that there is likely much more work to do,
  especially in the case of C++ as we have mostly focused on C so far.
* Because `-ast-print` computes its output from the AST structure, the
  output looks like the output of Clang's preprocessor.  Thus,
  includes and other macros are expanded, and the original formatting
  and comments are lost.  Such mangling of the source is unsuitable
  for permanent migration of an application from OpenACC to OpenMP.
  It's also unsuitable when targeting a different OpenMP compiler
  perhaps for a different target architecture where preprocessor
  macros and includes expand differently.

On the other hand, because `-fopenacc-print` is built on `Rewrite`, it
modifies the original input buffer and thus can avoid these problems
in most cases.  That is, `-fopenacc-print` examines the OpenACC
subtrees and the OpenMP subtrees computed by `TransformACCToOMP` as
needed to modify the input buffer in the manner requested by the
argument to `-fopenacc-print`.  For OpenMP subtrees containing
directives and other code not appearing in the original source and
thus not in the input buffer, it still employs `-ast-print`
functionality, but at least the above problems are not pervasive in
the output.  In the future, we might experiment with using some means
such as source locations to track which portions of an OpenMP subtree
were copied verbatim from the OpenACC subtree and then overriding
`-ast-print` functionality to print just those portions using the
original input buffer.

Interaction with OpenMP Support
===============================

`-fopenmp`
----------

Even though Clacc translates OpenACC to OpenMP, Clacc currently does
not support OpenACC and OpenMP in the same source.  Doing so would
require, for example, extensions to data sharing analyses to consider
the interactions between OpenACC and OpenMP directives and clauses.
Thus, Clacc reports an error diagnostic if `-fopenmp` is specified on
the Clang command line when OpenACC support is enabled by any
`-fopenacc*` option.  To implement this, Clacc extends the Clang
driver to just pass the relevant command-line options to the Clang
front end, and it extends the front end to produce the error
diagnostic.  Thus, specifying `-cc1` to bypass the driver does not
avoid the error diagnostic.

Discarding OpenMP (`-Wsource-uses-openmp`)
------------------------------------------

As usual when `-fopenmp` is not specified, the front end discards
OpenMP directives in the source during parsing, and
`-Wsource-uses-openmp` is available as usual to request warnings about
them.  Nevertheless, Clacc must enable OpenMP support in the front end
in order to build OpenMP subtrees without failing many assertions in
the OpenMP implementation, but enabling OpenMP support normally
prevents OpenMP directives from being discarded.  To implement all
this, Clacc extends the front end in two ways: (1) after confirming
the user did not request both OpenACC and OpenMP support, it enables
OpenMP support if OpenACC support is enabled, and (2) it discards
OpenMP directives during parsing if either OpenMP support is disabled
or OpenACC support is enabled.

`-fopenmp-*`
------------

Clacc permits all `-fopenmp-*` command-line options when OpenACC
support is enabled.  These options adjust various OpenMP features when
compiling the OpenMP translation.  To implement this, Clacc extends
Clang to check if OpenACC support is enabled everywhere it already
checks if OpenMP support is enabled.  However, so far, only
`-fopenmp-targets=<triples>` to specify desired offloading targets has
been tested, and it's only been tested for traditional compilation
mode.

It's not clear if `-fopenmp-*` options should be relevant to
source-to-source mode.  First, some options like
`-fopenmp-targets=<triples>` affect the OpenMP version Clang selects
by default, and that can affect semantics, diagnostics, and any
AST-printed code containing `_OPENMP`, but should Clacc let any of
that matter when compiling OpenACC?  Second, in experimental
implementations, we have observed that `-fopenmp-targets=nvptx64` adds
many declarations to the source code printed for `nvptx64`.  Would
offload bundling of the various versions of the source code be useful?

In general, the Clacc user should not have to be aware that OpenMP
support is being utilized when in traditional compilation mode.
However, the need to combine `-fopenmp-targets=<triples>` with
`-fopenacc` to enable offloading, for example, violates that
principle.  Moreover, diagnostics for `-fopenmp-*` are currently
expressed in terms of OpenMP even when OpenACC support is enabled.  In
the future, especially when Clacc is considered for upstreaming, Clacc
might develop its own `-fopenacc-*` options to be used instead.
Nevertheless, for now, we have concluded that the Clacc implementation
will be easier to keep in sync with upstream while the Clacc
implementation reuses the existing `-fopenmp-*` options with minimal
modifications.

`-fopenmp=<lib>`
----------------

Normally, `-fopenmp=<lib>` can be used to specify an alternate OpenMP
library.  However, Clang handles it as an alias for `-fopenmp`, so
it's also expected to enable OpenMP support.  We feel it would be
subtle and surprising to users if Clacc were to suppress the latter
behavior when OpenACC support is enabled, so it is currently not
possible to use `-fopenmp=<lib>` to specify an alternate OpenMP
library when OpenACC support is enabled.  Options like `-L` and `-l`
must be used instead.

OpenACC to OpenMP Mapping
=========================

This section details Clacc's planned mapping from OpenACC directives
and clauses to OpenMP directives and clauses.  If an OpenACC directive
or clause does not appear in this section, we haven't planned it yet.
`README-OpenACC-status.md` lists which OpenACC directives and clauses
Clacc already implements.

Notation
--------

For conciseness, we use the following notation when describing clauses
and data attributes:

* *pre* labels a data attribute that is predetermined by the compiler
  (that is, cannot be overridden by an explicit clause) and is not
  specified by an explicit clause.
* *imp* labels a data attribute that is implicitly determined by the
  compiler (that is, can be overridden by an explicit clause) and is
  not specified by an explicit clause.
* *exp* labels a clause, possibly specifying a data attribute, that is
  explicitly specified in the source.
* *not* labels a clause that is not explicitly specified.
* The notation *L C* -> *L' C'* specifies that clause or data
  attribute *C* under the condition identified by label *L* maps to
  clause or data attribute *C'* under the condition identified by
  label *L'*, where a label is *pre*, *imp*, *exp*, or *not*.
* The notation *L*|*L' C* -> *L'' C'* specifies both of the following
  mappings:
    * *L C* -> *L'' C'*
    * *L' C* -> *L'' C'*
* Mappings for per-variable data attributes and clauses are per
  variable and per directive.
* Mappings for other clauses are per directive.
* Where arguments to clauses are not specified on either end of the
  mapping, the mapping maintains the arguments as they are even if the
  clause name or position changes.

Prescriptive vs. Descriptive OpenACC
------------------------------------

The mapping in this section represents a conservative choice intended
to always achieve correct OpenACC behavior.  As Clacc evolves to
support a descriptive interpretation of OpenACC and the requisite
compiler analyses, this mapping will represent the base choice from
which Clacc will look for deviations to improve performance of the
application, and this mapping will represent the fall back choice if
Clacc fails to find better mappings.  Under Clacc's current
prescriptive interpretation of OpenACC, Clacc supports no such
analyses and so effectively always falls back to this mapping.

Explicit vs. Implicit OpenMP Clauses
------------------------------------

One theme throughout Clacc's mapping is that Clacc does not rely on
implicit or predetermined attributes of OpenMP except for cases where
an explicit clause is not permitted or is difficult to produce.  That
is, Clacc tries to make the exact behavior it intends to produce as
explicit as possible in the generated OpenMP for the sake of
debugging. Thus, -> *exp* appears frequently below.

Clause Aliases
--------------

Some OpenACC clauses, such as `pcopy`, are aliases for others clauses,
such as `copy`.  Clacc handles the semantics and mapping for a clause
alias the same as for the aliased clause, so clause aliases are not
documented further in this section.

Semantic Clarifications
-----------------------

While developing this mapping, we found we had to make assumptions
about a number of aspects of OpenACC semantics in C that are not clear
in the OpenACC specification.  In many cases, it was the related
behavior of the Clang OpenMP implementation that brought the need for
those assumptions to our attention.  We describe those assumptions in
this section.

### Basic Data Sharing ###

* It is an error if a variable appears in more than one occurrence of
  any one of *exp* `copy`, *exp* `copyin`, *exp* `copyout`, *exp*
  `firstprivate`, *exp* `private`, or *exp* `reduction` on an OpenACC
  directive.  Notes:
    * The main motivation for this error is that such a repetition is
      likely a mistake.
    * gcc 7.4.0 also reports errors for this case, but pgcc 19.4-0
      does not.
    * OpenMP 5.0 sec. 2.19.4 p. 282 L7-9 says, "A list item may not
      appear in more than one clause on the same directive, except
      that it may be specified in both firstprivate and lastprivate
      clauses."  Thus, if Clacc did not report such duplicate clauses
      as errors, it would have to discard them when generating OpenMP.
* It is an error if a variable appears in more than one of *exp*
  `copy`, *exp* `copyin`, *exp* `copyout`, *exp* `firstprivate`, or
  *exp* `private` on an OpenACC directive.  Notes:
    * Relative to `copy`, `copyin`, and `firstprivate`, `copyout` and
      `private` have a contradictory specification for initialization
      of the local copy of the variable.
    * Relative to `copyin`, `firstprivate`, and `private`, `copy` and
      `copyout` have a contradictory specification for storing data
      back to the original variable.
    * On a combined construct, `copy`, `copyin`, `copyout`, and
      `firstprivate` apply to the effective `acc parallel`, and
      `private` applies to the effective `acc loop`.  Thus, specifying
      a variable in any of the former clauses and also in `private`
      wouldn't be contradictory.  However, it is surely a mistake as
      it specifies copying in a value you cannot then access or
      copying out an unchanged value.  Thus, the above restriction
      applies to a combined construct as well.
    * TODO: Is it useful to or does any existing code combine `copyin`
      or `copyout` with `firstprivate` or `private` expecting the
      copied value to be used or assigned in a later or earlier
      compute region?
* It is an error if a variable has *exp* `reduction` as well as either
  *exp* `firstprivate` or *exp* `private` on an OpenACC directive.
  Notes:
    * These have contradictory specifications for initialization of
      the local copy of the variable and for storing data back to the
      original variable.
    * On a combined construct, `firstprivate` applies to the effective
      `acc parallel`, and `reduction` applies to the effective `acc
      loop`.  Thus, specifying a variable in both wouldn't be
      contradictory.  However, it is surely a mistake as you cannot
      access the reduced value.  Thus, the above restriction applies
      to a combined construct as well.
* *imp*|*exp* `copy`, *exp* `copyin`, *exp* `copyout`, *exp*
  `firstprivate`, *exp* `private`, or *exp* `reduction` for a variable
  of incomplete type is an error.  Notes:
    * A local copy must be allocated in each of these cases, but
      allocation is impossible for incomplete types.
    * It does not appear possible for any clause other than `copy` to
      be *imp* for a variable of incomplete type.
* *exp* `private` or *exp* `reduction` for a `const` variable is an
  error.  Notes:
    * The local copy of a `const` private variable would remain
      uninitialized throughout its lifetime.
    * A reduction assigns to both the original variable and a local
      copy after its initialization, but `const` prevents that.
    * `copy` and `copyout` are strange cases.  Technically, each
      assigns to the original, and `const` prevents that.  However,
      there are several arguments for why each should be permitted for
      a `const` variable:
        * For shared memory, it's supposed to be fine to ignore *exp*
          `copy` and *exp* `copyout` (among other clauses) entirely,
          so `const` is harmless in that case.  An implementation for
          discrete memory could optimize by not copying back to the
          original variable because the value shouldn't change because
          it's `const`, so `const` is actually helpful here instead of
          problematic.  In the case of `copyout`, it could be argued
          that the value to be copied back could be an uninitialized
          value instead of the original value, but it could also be
          argued that's poor usage of `copyout`.
        * It should be fine to reference a `const` non-scalar within
          an `acc parallel` region even though the non-scalar is
          declared outside the region, but the `acc parallel` has
          *imp* `copy` for such a non-scalar.  Thus, *imp* `copy` must
          be permitted for the non-scalar, and so then should *exp*
          `copy`.
        * Clacc translates `copy` or `copyout` to OpenMP's `map`
          clause with a map type of `tofrom` or `from`, and the OpenMP
          implementation permits those for `const` variables.
    * `copyin` and `firstprivate` are fine for a `const` variable.
      The local copy will have the original variable's value
      throughout its lifetime.
    * It does not appear possible for any clause other than `copy` and
      `firstprivate` to be *imp* for a `const` variable.  `private` is
      *imp* for loop control variables, but they obviously cannot be
      `const` anyway.
* An *imp* `copy` for a reduction variable overrides an *imp*
  `firstprivate` when the variable is a scalar.  Text to make this
  overriding behavior clear has been proposed for inclusion in the
  OpenACC spec after 2.7.
* While OpenACC does not define a `shared` clause, this design
  document and Clacc's implementation use the concept of *imp*
  `shared` for any variable that is referenced within an OpenACC
  `loop` construct, that is declared outside it, and for which OpenACC
  semantics do not specify `private` or `reduction`.  Notes:
    * `shared` really just indicates that references to the variable
      within the `loop` construct reference the original variable.
    * In many cases, Clacc translates `shared` to OpenMP's `shared`
      clause.  However, `omp distribute` and `omp simd` do not accept
      *exp* `shared`.  As noted in the mappings below, Clacc relies on
      OpenMP implicit data sharing attributes in those cases, and the
      semantics are the desired OpenACC semantics.

### Reductions ###

* If *exp* `reduction(`*o*`:`*v*`)` on an `acc loop`, and if *v* is
  gang-private, then:
    * If the loop is sequential, the reduction is trivial.
    * If the loop is gang-partitioned, the specified gang reduction is
      a trivial reduction per gang.
    * Notes:
        * Text to clarify that such reductions are trivial has been
          proposed for inclusion in the OpenACC spec after 2.7.
        * In the case of a trivial gang reduction, there can still be
          a non-trivial worker or vector reduction if the loop is also
          worker-partitioned or vector-partitioned.
        * A trivial reduction reduces across only one thread.  Thus,
          the reduction specifies the creation of a single private
          copy of *v* that is initialized and later merged back to the
          original *v* according *o*.  The only way that behavior
          appears to be different than just discarding the reduction
          is if either (1) the loop body performs an operation on *v*
          that's inconsistent with *o*, or (2) there's a race on
          writes to the original *v* that's somehow avoided when
          postponing the write to the exit of the loop.  Clacc makes
          the assumption that these are likely broken use cases and
          need not be supported.  Thus, Clacc implements these trivial
          reductions by simply discarding them in the translation to
          OpenMP.
* If *exp* `reduction(`*o*`:`*v*`)` on an `acc loop`, and if *v* is
  gang-shared, then *imp* `reduction(`*o*`:`*v*`)` on the parent `acc
  parallel`.  Notes:
    * Thus, Clacc handles a loop reduction for a gang-shared variable
      as a gang reduction even if the loop is not gang-partitioned and
      even if the loop is sequential.  This subtle behavior comes from
      a strict reading of the spec since OpenACC 1.0.  Text to make
      this behavior clearer has been proposed for inclusion in the
      OpenACC spec after 2.7.
    * Clacc interprets this gang reduction as an *imp* `reduction` on
      the `acc parallel` to facilitate the translation to OpenMP (for
      example, reductions cannot be specified on `omp distribute` but
      can be specified on `omp target teams`).  All references to *v*
      within the `acc parallel` then refer to gang-private copies of
      *v*.  However, under OpenACC 2.7 (and earlier), all references
      to *v* within the `acc parallel` should still refer to the
      original gang-shared *v* instead.  Text to specify that accesses
      to the original gang-shared variable are undefined throughout
      the `acc parallel` has been proposed for inclusion in the
      OpenACC spec after 2.7.  In that case, either interpretation is
      conforming.
* If *exp* `reduction(`*o*`:`*v*`)` on an `acc loop`, and if the loop
  is gang-partitioned, then *imp* `copy(`*v*`)` on the parent `acc
  parallel` overriding any *imp* `firstprivate(`*v*`)` as long as all
  of the following conditions hold:
    * *not* `copy(`*v*`)`, *not* `copyin(`*v*`)`, *not*
      `copyout(`*v*`)`, *not* `firstprivate(`*v*`)`, *not*
      `private(`*v*`)`, and *not* `reduction(`*o'*`:`*v*`)`, on that
      `acc parallel` and on any `acc loop` nested between it and the
      gang-partitioned `acc loop`.
    * There is no local declaration of *v* nested between the `acc
      parallel` and the gang-partitioned `acc loop`.
    * Notes:
        * By converting *v* from gang-private to gang-shared, this
          rule can trigger the previous rule to convert a trivial gang
          reduction to *imp* `reduction` on the `acc parallel`.
        * This rule does not follow OpenACC 2.7.  However, in our
          experiments so far, both gcc 7.3.0 and pgcc 18.10-0 appear
          to perform gang reductions and copy the reduction variable's
          values to and from the device as specified by this rule.
          This is true even when, without this rule, the reduction
          variable should be *imp* `firstprivate`.
        * There is discussion among the OpenACC technical committee
          about adding a rule like this one to the OpenACC spec after
          2.7.  However, every proposal considered so far produces
          surprising or non-portable behavior in some cases, so the
          future of this behavior is unclear.
* It is an error if, on a particular OpenACC directive, there exist
  multiple *imp|exp* `reduction` with different reduction operators
  for a single variable *v*.  Moreover, *imp* `reduction` is included
  when applying OpenACC 2.7 sec. 2.9.11 L1580-1581.  Notes:
    * That passage specifies this restriction for *exp* `reduction` on
      nested constructs, but it doesn't discuss the case where sibling
      `acc loop` constructs specify conflicting gang reductions or
      where multiple conflicting reductions appear on the same
      directive.
* Variable type restrictions for `reduction` are specified in
  `README-OpenACC-status.md` as that is a highly user-visible issue.

### Integer Expression Arguments ###

* It is an error if an argument to `num_gangs`, `num_workers`, or
  `vector_length` is not a positive integer expression.  If the
  argument to `vector_length` is not also a constant expression, Clacc
  does not use it and reports a warning diagnostic.  See
  `README-OpenACC-status.md` for rationale.

### Loop Control Variables ###

* For an `acc loop` directive with *exp* `seq` such that the loop
  control variable is just assigned instead of declared in the init of
  the attached `for` loop, the loop control variable is *imp*
  `shared`.  Notes:
    * Otherwise, there appears to be no way to tell an aggressive
      OpenACC compiler to leave such a loop as a normal sequential
      loop in C, where the variable would normally have `shared`
      semantics in that its final value is visible after the loop.
    * OpenACC 2.7 sec. 2.6.1 L876-879 only requires that the variable
      is private to each thread executing the loop.  Only one thread
      executes a sequential loop, and it's the same thread that
      executes outside the loop.  The specification does not appear to
      clarify whether the variable's privacy is also limited to the
      loop's region.  Clacc uses the interpretation that, as explained
      above, seems more useful.
    * In our experiments, this choice is consistent with pgcc 19.4-0,
      but gcc 8.3.0 assumes *pre* `private` instead.
* For any other `acc loop` directive, the loop control variable is
  *pre* `private`.  Notes:
    * OpenACC 2.7 sec. 2.6.1 L876-879 only requires that the variable
      is private to each thread executing the loop.  Clacc interprets
      this as *pre* `private`, which additionally means none of those
      private variables are visible after the loop.
    * This choice is not consistent with the previous case.  However,
      because the deciding factors are the presence of *exp* `seq` and
      whether the loop control variable is declared or just assigned,
      it is straight-forward for the OpenACC programmer to determine
      the visibility of the loop control variable without, for
      example, predicting the compiler's parallelization decisions.
    * In our experiments, this choice is consistent with gcc 8.3.0.
      However, pgcc 19.4-0 appears to let each thread (within each
      gang within each worker) retain the value it would have after
      incrementing once past only the iterations it performs, so the
      value visible afterward depends on the exact partitioning and
      which thread is the master and thus continues to run after the
      loop.  Thus, pgcc seems the most consistent with the exact
      wording in the spec.
    * This choice is consistent with OpenMP 4.5's choice for
      `distribute` (`gang`) and `parallel for` (`worker`)
      (sec. 2.15.1.1 p. 179 lines 24-25).
    * This choice is not consistent with OpenMP 4.5's choice for
      `simd` (`vector`) (sec. 2.15.1.1 p. 179 lines 26-27), which
      instead specifies pre `linear`, which has `lastprivate`-like
      semantics.
    * This choice is reasonably straight-forward to translate to
      OpenMP, but the pgcc approach would be harder to translate to
      OpenMP.  For example, in our experiments, `lastprivate` produces
      either the original value from before the loop or the value
      after the entire loop and not the value after only the
      iterations performed by the thread.
    * It is not clear whether the values produced by the pgcc approach
      are actually useful given their dependence on the exact
      partitioning chosen by the compiler.
* For any `acc loop` directive, *exp* `reduction` is not permitted on
  a loop control variable regardless of its data sharing.  Notes:
    * For consistency with parallelized `acc loop` directives, this
      rule applies for sequential `acc loop` directives even
      though the mapping for them discards the `reduction`.
    * If the loop control variable is declared instead of just
      assigned in the init of the attached `for` loop, any reference
      to the variable's name in the directive's clauses refers to a
      different variable, so this rule does not apply.
    * Clang's OpenMP implementation also enforces this constraint.
      That makes sense by the OpenMP spec because an OpenMP
      `reduction` is a data sharing attribute and a loop control
      variable has a different predetermined data sharing attribute.
    * For OpenACC, gcc 7.2.0 also enforces this constraint, but pgcc
      18.4-0 does not enforce it.

### Implicit Gang Clauses ###

The OpenACC technical committee has discussed [clarifying the behavior
of *naked* loop
directives](https://github.com/OpenACC/openacc-spec/issues/125).  In
these discussions, a naked loop directive is an `acc loop` directive
with *not* `seq`, *not* `gang`, *not* `worker`, and *not* `vector`.
The problem is that the OpenACC spec implies that such a loop should
run in gang-redundant mode, but existing OpenACC compilers (GCC and
PGI) usually gang-partition it.  The difference between these modes is
often important to semantic correctness besides just performance, and
understandably some existing OpenACC programs were written to expect
the semantics that existing compilers provide.  This issue has not yet
been resolved as of OpenACC 2.7.

Clacc attempts to mimic the behavior of existing OpenACC compilers by
adding *imp* `gang` to `acc loop` directives, but many questions
remain about exactly how *imp* `gang` placement should be computed.
Currently, it works as follows in Clacc:

* Any conversion of `acc loop` constructs with *exp* `auto` to
  sequential loops is performed before computing *imp* `gang`
  placement.  Notes:
    * Currently, Clacc converts all `acc loop` constructs with *exp*
      `auto` to sequential loops.  Obviously, as Clacc grows a
      descriptive interpretation of `auto`, some such constructs will
      be handled as if they have *imp* `independent` instead.
    * Performing `auto` conversions first so that *imp* `gang`
      placement depends on them places more optimization power in the
      hands of the compiler.  For example, in an `acc loop auto` nest,
      the compiler could choose any loop level for gang partitioning.
      However, the difference between gang-partitioned mode and
      gang-redundant mode can have an important impact on the
      semantics of a program.  The OpenACC programmer specified `auto`
      presumably because he cannot predict the outcome of `auto`
      conversions, and thus now he cannot predict at which of the many
      loop levels these semantics will shift.
    * Performing *imp* `gang` placement first so it does not depend on
      the outcome of `auto` conversions can reduce the possible
      semantics of an OpenACC program.  In the `acc loop auto` nest
      example, the loop nest would be either entirely gang-redundant
      or entirely gang-partitioned.
    * TODO: In our experiments so far, we have not been able to
      determine what approach pgcc 19.4-0 follows generally, and it's
      not clear what's really better here.  As the OpenACC technical
      committee standardizes an approach, we will adjust Clacc.
* Within that context, an `acc loop` construct has *imp* `gang` if all
  of the following are true:
    * *not* `gang`, *not* `worker`, and *not* `vector`.  Notes:
        * The goal here is to give the OpenACC programmer some means
          to specify partitioning exactly as he sees fit.
        * Interestingly, without this constraint, it would be
          impossible to specify gang-redundant mode combined with
          worker-partitioned or vector-partitioned mode.
    * *exp* `gang` would be permitted.  Notes:
        * Based on OpenACC 2.7, *exp* `gang` would not be permitted on
          any `acc loop` construct that has (a) an ancestor `acc loop`
          construct with *exp* `gang`, *exp* `worker`, or *exp*
          `vector`, (b) *exp* `seq`, or (c) a nested `acc loop`
          construct with *exp* `gang`.
        * These restrictions are relaxed a bit for *imp* `gang`
          because `auto` conversions are performed first.  For
          example, an `acc loop auto gang` that becomes a sequential
          loop prevents a nested `acc loop` from having an *exp*
          `gang` clause but not from having an *imp* `gang` clause.
          TODO: This behavior seems inconsistent.  Should we change
          it?  In general, the semantics of `auto` plus `gang` are
          still being clarified by the OpenACC technical committee.
    * There is no ancestor `acc loop` construct that is permitted to
      have *exp* `gang`.  Notes:
        * The point here is to chose the outermost construct possible.

Parallel Directives
-------------------

Clacc's current mapping of an `acc parallel` directive and its clauses
to OpenMP is as follows:

* `acc parallel` -> `omp target teams`
* *imp*|*exp* `copy` -> *exp* `map` with a `tofrom` map type.
* *imp*|*exp* `copyin` -> *exp* `map` with a `to` map type.
* *imp*|*exp* `copyout` -> *exp* `map` with a `from` map type.
* *imp*|*exp* `firstprivate` -> *exp* `firstprivate`
* *exp* `private` -> *exp* `private`
* *imp*|*exp* `reduction` -> *exp* `reduction`
* *exp* `num_gangs` -> *exp* `num_teams`
* If *exp* `num_workers` with a non-constant-expression argument, and
  if there is a nested worker-partitioned `acc loop`, then *exp*
  `num_workers` -> wrap the `omp target teams` in a compound statement
  and declare a local `const` variable with the same type and value as
  the *exp* `num_workers` argument.
* Else if *exp* `num_workers` with a non-constant-expression argument
  that potentially has side effects, then *exp* `num_workers` -> wrap
  the `omp target teams` in a compound statement and insert a
  statement that casts the argument's expression to `void`.
* Else, translation discards *exp* `num_workers`.  Notes:
    * A constant-expression argument here might be used by a nested
      worker-partitioned `acc loop`.
* If *exp* `vector_length` with a non-constant-expression argument
  that potentially has side effects, then *exp* `vector_length` ->
  wrap the `omp target teams` in a compound statement and insert a
  statement that casts the argument's expression to `void`.  Moreover,
  report a warning diagnostic that `vector_length` is being ignored.
* Else, translation discards *exp* `vector_length`.  Notes:
    * A constant expression argument here might be used by a nested
      vector-partitioned `acc loop`, but a non-constant-expression
      argument is not (this follows "Semantic Clarifications" above).

Loop Directives
---------------

Clacc does not yet support the `acc kernels` directive or an orphaned
`acc loop` directive, so an `acc loop` directive must appear in an
`acc parallel` directive.

### Sequential Loops ###

Clacc treats an `acc loop` directive as sequential if any of the
following are true:

* *exp* `seq`
* *exp* `auto`
* *not* `gang`, *not* `worker`, *not* `vector`, and not *imp* `gang`
* Notes:
    * The latter two cases normally depend on the OpenACC compiler to
      determine the best way to parallelize the loop.  Again, Clacc
      does not yet support the necessary analyses and so depends on
      the application developer to prescribe the parallelization, so
      Clacc makes the conservative choice of a sequential loop
      instead.
    * The third case (without the other two) would certainly be the
      more straightforward case to improve because OpenACC specifies
      that the loop iterations are then required to be
      data-independent (that is, *imp*|*exp* `independent`).  This is
      a case where a simple AST-level analysis could go a long way for
      existing OpenACC applications that expect a descriptive
      interpretation: Clacc could add whichever of `worker` or
      `vector` doesn't conflict with other clauses on ancestor or
      nested loops.
    * Actually, the placement of *imp* `gang` is already a step in
      this direction.  Unlike an *imp* `worker` or *imp* `vector`,
      it's necessitated due to the shift in semantics between
      gang-redundant and gang-partitioned mode, and it will likely be
      specified more exactly by the OpenACC standard in the future.
      See "Implicit Gang Clauses" above for details.

Clacc's current mapping of a sequential `acc loop` directive and its
clauses to OpenMP is as follows:

* Translation discards the `acc loop` directive and the following
  clauses or attributes:
    * *exp* `seq`, *exp* `independent`, *exp* `auto`
    * *exp* `gang`, *exp* `worker`, *exp* `vector`
    * *exp* `collapse`
    * *pre* `private` for a loop control variable that is declared in
      the init of the attached `for` loop
    * *imp* `shared`, *exp* `reduction`
    * Notes:
        * For a loop control variable that is declared in the init of
          the attached `for` loop, a private copy is already made for
          the one thread executing the loop.
        * *imp* `shared` is only for variables referenced within the
          loop but declared outside the loop, and these are already
          shared by the simple C `for` loop.
        * *exp* `reduction` for a gang-private variable is discarded
          here because it is a trivial reduction, as discussed under
          "Semantic Clarifications" above.
        * *exp* `reduction` for a gang-shared variable is discarded
          here and is implemented instead via an *imp* `reduction` on
          the `acc parallel`, as discussed under "Semantic
          Clarifications" above.
* Otherwise, *pre*|*exp* `private` -> wrap the loop in a compound
  statement and declare an uninitialized local copy of the variable.
  Notes:
    * exp `private` just needs to be local to the one thread executing
      the loop, and so creating a new local variable is sufficient.

A sequential `acc loop` directive is gang-redundant, worker-single,
vector-single mode.  Thus, as far as partitioning is concerned, simple
C `for` loops are sufficient.  We considered mapping instead to
various OpenMP directives so that `private` and `reduction` clauses
could simply be translated to OpenMP clauses.  To understand the
desired properties of the chosen mapping described above, it's
important to understand why each of those considered mappings would
fail to behave correctly:

* `omp parallel for num_threads(1)` does not behave as a sequential
  loop in at least two ways:
    * It makes the loop control variable *pre* `private`, but that's
      not how Clacc treats an `acc loop seq` directive's loop control
      variable that is assigned but not declared in the init of the
      attached `for` loop.
    * When the loop control variable is modified in the body of the
      loop, behavior is not defined because the init, cond, and incr
      expressions alone must determine the number of iterations.  In
      our experiments, the current Clang OpenMP implementation
      observes only those expressions and ignores even the simplest
      modification in the body.  OpenACC 2.7 sec. 2.9 L1438-1439
      describes the related OpenACC requirement, which does not apply
      in the case of `seq`, so the mapping shouldn't impose this
      restriction.
* `omp parallel num_threads(1)` (drops the `for` from the above
  directive) avoids the above problems.  However, for either mapping,
  `acc loop seq` couldn't enclose an `acc loop gang` or be nested
  within an `acc loop vector` because `omp parallel` cannot enclose an
  `omp distribute` or be nested within an `omp simd`.

### Parallelized Loops ###

If Clacc does not treat an `acc loop` directive as sequential as
described in the previous section, then it treats it as parallelized.
In that case, Clacc's current mapping of the `acc loop` directive and
its clauses to OpenMP is as follows:

* `acc loop` -> `omp`
* *imp*|*exp* `gang` -> `distribute`
* *exp* `worker` -> `parallel for`
* If neither this nor any ancestor `acc loop` is gang-partitioned or
  worker-partitioned, then -> `parallel for` and -> *exp*
  `num_threads(1)`.  Notes:
    * We add `parallel for` for this case because OpenMP does not
      permit `omp simd` directly inside `omp target teams`.
    * An alternative might be to translate to `omp simd` directly
      inside `omp parallel`, but OpenMP does not have a combined `omp
      parallel simd` directive, leading us to question the semantics.
* *exp* `vector` -> `simd`
* The output `distribute`, `parallel for`, and `simd` OpenMP directive
  components are sorted in the above order before all clauses,
  including the above `num_threads(1)`, regardless of the input clause
  order.
* If *exp* `worker`, then *exp* `num_workers` from ancestor `acc
  parallel` -> *exp* `num_threads` where the argument is either (1)
  the original *exp* `num_workers` argument if it is a constant
  expression or (2) otherwise an expression containing only a
  reference to the local `const` variable generated for that *exp*
  `num_workers`.  Notes:
    * For the ancestor `acc parallel` and for all OpenACC directives
      nested between it and this `acc loop`, Clacc leaves the OpenMP
      data sharing attribute for the local `const` variable for
      `num_workers` as implicit.  Because the variable is `const`,
      private copies are not useful, so sharing is probably most
      efficient, but not all OpenMP directives permit an *exp*
      `shared` clause.  Thus, relying on implicit data sharing
      attributes throughout simplifies the implementation.
* If *exp* `vector`, then *exp* `vector_length` with a
  constant-expression argument from ancestor `acc parallel` -> *exp*
  `simdlen`.
* `collapse` -> `collapse`
* If *exp* `worker` or if this and every ancestor `acc loop` until the
  ancestor `acc parallel` is not gang-partitioned and not
  worker-partitioned, then *imp* `shared` -> *exp* `shared`.
* Else, *imp* `shared` -> *imp* `shared`.  Notes:
    * This case must map to *imp* `shared` because `omp distribute` or
      `omp simd` without `parallel for` (which Clacc adds for `worker`
      or to be able to nest `omp simd` directly within `omp target
      teams`) does not support a `shared` clause, so we must rely on
      OpenMP implicit data sharing rules then.
* *pre* `private` for a loop control variable that is declared in the
  init of the attached `for` loop -> *pre* `private`.  Notes:
    * Mapping to *exp* `private` would be erroneous because it would
      refer to a variable from the enclosing scope.
* If *exp* `vector` and the loop control variable is just assigned
  instead of declared in the init of the attached `for` loop, then
  *pre*|*exp* `private` for that variable -> *pre* `linear`.  Then,
  wrap the `omp simd` in a compound statement, and declare an
  uninitialized local copy of the loop control variable.  Notes:
    * For `omp simd`, OpenMP 4.5 specifies *pre* `linear` here
      (sec. 2.15.1.1 p. 179 lines 26-27), so we cannot translate to
      *exp* `private`.
    * Clacc doesn't attempt to map to *exp* `linear` because (1) the
      OpenMP spec says the step must be the increment from the
      attached loop, (2) the OpenMP spec says the default step for an
      *exp* `linear` is 1, and (3) we don't want to have to implement
      extracting the increment from the attached loop when we can just
      rely on the behavior of *pre* `linear` and thus on Clang's or
      some other target compiler's OpenMP implementation to extract it
      for us.
* In all other cases, *pre*|*exp* `private` -> *exp* `private`.
* If *exp* `worker` or *exp* `vector`, then *exp* `reduction` -> *exp*
  `reduction`.
* Else, translation discards *exp* `reduction`.  Notes:
    * *exp* `reduction` for a gang-private variable is discarded here
      because it is a trivial gang reduction, as discussed under
      "Semantic Clarifications" above.
    * *exp* `reduction` for a gang-shared variable is discarded here
      and is implemented instead via an *imp* `reduction` on the `acc
      parallel`, as discussed under "Semantic Clarifications" above.

Combined Directives
-------------------

The only combined OpenACC directive Clacc supports so far is `acc
parallel loop`, which is translated in two stages:

* **Translate from the combined OpenACC directive to effective
  separate directives**: Clacc performs this stage during the parse
  while constructing the `acc parallel loop` directive's AST node.
  Clacc builds the effective AST subtree containing the `acc parallel`
  and `acc loop` directives, and then it records the AST subtree for
  the outermost of those directives, `acc parallel`, as a hidden
  subtree of the `acc parallel loop` node.  The associated code block
  for the `acc parallel loop` node is recorded like a normal AST child
  for each of the `acc parallel loop` node and the `acc loop` node.
* **Translate from effective separate directives to OpenMP
  directives**: This stage is performed by `TransformACCToOMP` just as
  it normally would be for the separate directives.  That is, the `acc
  parallel loop` node delegates to the `acc parallel` node.

The relationship between the `acc parallel loop` node and the `acc
parallel` node is similar to the relationship between any non-combined
OpenACC directive's node and its OpenMP node.  Moreover, it
effectively replaces that relationship.  That is, most AST traversals,
including `-ast-print`, visit the `acc parallel loop` node and skip
over the hidden subtree for its effective `acc parallel` directive
because the `acc parallel loop` node without the `acc parallel`
subtree represents the original source.  The `-ast-dump` facility
prints the `acc parallel` node as a specially marked child node, which
prints its OpenMP node as a specially marked child node.  For codegen
to LLVM IR, the `acc parallel loop` node delegates to its effective
`acc parallel` node, which delegates to its OpenMP node.

Because the second stage of translation above is delegated to the
effective `acc parallel` directive, `acc parallel loop` does not
require a mapping to OpenMP.  However, it and its clauses do require a
mapping to its effective directives for the sake of the first stage,
as follows:

* `acc parallel loop` -> `acc parallel`, whose associated code block
  is an `acc loop`, whose associated code block is the associated code
  block from the `acc parallel loop`.
* *exp* `private` -> *exp* `private` on the effective `acc loop`.
* *exp* `reduction` -> *exp* `reduction` on the effective `acc loop`.
* Each remaining explicit clause is permitted on only one of the
  separate OpenACC directives, and so it is mapped to that directive.
* Predetermined and implicit attributes do not require a mapping to
  the effective directives because there are none because semantic
  analysis computes them only on the effective directives.

Unmappable Features
-------------------

It might prove to be impossible to map some OpenACC features to
standard OpenMP.  For such features, our plan is to map to OpenMP
language or runtime extensions, which we will implement as necessary.

When source-to-source translation (as opposed to normal full
compilation) is enabled, we will implement diagnostics to identify
uses of such features unless those diagnostics are inexact and prove
to have too many false positives.  In the worst cases, we would
identify such features at run time.

The following is a list of OpenACC features we have identified that
might not be possible to map to OpenMP, but we are still investigating
possible solutions:

* `vector_length` with a non-constant-expression argument because
  `simdlen`, to which `vector_length` is translated, requires a
  constant expression.  In the future, Clacc might support alternative
  mappings for partitioning types, either configured by the user or
  computed automatically.  If `acc loop vector` were mapped to `omp
  parallel for`, `vector_length` with a non-constant-expression
  argument would be possible.
* A gang reduction specified on an orphaned `acc loop` directive
  because the enclosing compute construct to which the reduction would
  normally be applied during translation is not statically visible.  A
  restriction against this case already appears in OpenACC 2.7 (and
  earlier), but it does not include the case of a gang reduction for a
  gang-shared variable on a non-gang loop.  Text has been proposed for
  inclusion in the OpenACC spec after 2.7 to clarify.
* Orphaned `acc loop` directive that observes `num_workers` and
  `vector_length` because the enclosing compute construct from which
  those clauses would normally be applied during translation is not
  statically visible.
* Multiple reference counters because OpenMP has just one reference
  counter.

C++ Issues
----------

* Restrictions for private and reduction clauses related to
  const-qualified types could be relaxed in the case of mutable
  fields.  The OpenMP implementation does this, as hinted by OpenMP
  5.0 sec. 2.19.1.1 phrase "with no mutable members".
